%!TEX root = ../head.tex

\chapter{Vorlesung}
\section{Einführung}

\subsection{Big Data}
"Big Data hat die Chance die geistige Mittelschicht in Hartz IV zu bringen"

\section{Vorlesung}
\subsection{ZIH}
\begin{itemize}
	\item HAEC
	\item CRESTA Perfomrance optimization
	\item MPI correctness checking: MUST
	\item Architecture of the new system (HRSK-II)
\end{itemize}
\subsection{Begriffe und Definitionen}
\begin{itemize}
	\item Der Begriff Rechnerarchitektur wurde von dem englischsprachigen Begriff computer architecture abgeleitet
	\item Computer architecture ist eine Teildisziplin des Wissenschaftsgebietes computer enginering, welches die überwiegend ingeniermäßige Herangehensweise beim Entwurf und der Optimierung von Rechnersystemen deutlich zum Ausdruck bringt.
	\item Zwei Deutungen des englischen Begriffs "Architecture"
	\item Zur Definition der Rechnerarchitektur
	\begin{itemize}
		\item Architektur: Ausdruck insbesondere der Möglichkeiten der Programmierschnittstelle
		\begin{itemize}
			\item Maschinenbefehlssatz
			\item Registerstruktur
			\item Adressierungsmodi
			\item Unterbrechungsbehandlung
			\item Ein- und Ausgabe-Funktionalität
		\end{itemize}
		\item Komponenten / Begriffsbildung
		\begin{itemize}
			\item Hardwarestruktur
			\item Informationsstruktur (Maschinendatentypen)
			\item Steuerungsstruktur
			\item Operationsprinzip
		\end{itemize}
	\end{itemize}
	\item Taxonomie
	\item Dreiphasenmodell zum Entwurf eins Rechnersystems
	\begin{itemize}
		\item Bottom-up (Realisierung \(\to\) Implementierung \(\to\) Rechnerarchitektur)
		\item Top-down (Rechnerarchitektur \(\to\) Implementierung \(\to\) Realisierung)
		\item Rückwirkungen durch den technologischen Stand						\end{itemize}
\end{itemize}

\section{VL}
\subsection{Modifiziertes Dreiphasenmodell zum Entwurf eines RS}
\subsubsection{Befelhlssatzarchitektur}
\subsubsection{Implementierung}
\subsubsection{Realisierung}
\subsection{Architektur-Definition (Tanenbaum)}
Den Satz von Datentypen, Operationen und Merkmalen jeder Ebene bezeichnet man als ihre Architektur. Die Architektur betrifft die Aspekte, die für den Benutzer der jeweiligen Ebene sichtbar sind.
\subsection{Architektur-Definition (Hennessy/Patterson)}
We use the term instruction set architecture (ISA) to refer to the actual programmervisible instruction set in this book. the ISA serves as the boundary betweeen the software and hardware. \\ The implementation of a computer has two components: organization and hardware.
\subsection{Einflusskomplexe}
\begin{itemize}
	\item Die Rechnerarchitektur steht in Wechselwirkung mit zahlreichen benachbarten Disziplinen
	\begin{itemize}
		\item Betriebssysteme
		\begin{itemize}
			\item Konzepte aus dem Bereich Betriebssysteme werden durch Rechnerkomponenten unterstützt (z.B.: Virtueller Speicher/ I/O-Instruktionen)
			\item Andererseits werden durch moderne Rechnerarchitektur-Konzepte neue Anforderungen and die Betriebssysteme gestellt (z.B.: Erweiterung für Parallelarbeit)
		\end{itemize}
		\item Topologie
		\begin{itemize}
			\item Ursprünglich Teilgebiet der Mathematik zur Untersuchung der Struktur von Punktmengen und Räumen einschließlich ihrer Klassifizierung
			\item Daraus folgte: Gestaltung von Verbindungseinrichtungen in Multiprozessorsystemen (3-D Hypercube, D-Gitter)
		\end{itemize}
		\item Hardware-Entwurf
		\begin{itemize}
			\item Die Sammlung von Anforderungen bildet die strukturelle und organisatorische Entwurfsspezifikation der Teilkomponenten eines Rechners
			\item Darstellung: Very-High-Scale-Hardware-Description-Language (VHDL)
		\end{itemize}
		\item Compilerbau und Softwaretechnik
		\begin{itemize}
		\item Codegenerator eines Compilers hänt von Architektur und Befehlssatz des Zielprozessors ab.
			\item Intel-Titanium-Prozessor: EPIC-Architektur
		\end{itemize}
		\item Software-Entwurf
		\begin{itemize}
			\item Nutzung unterschiedlicher Programmierparadigmen und -modelle zur bestmöglichen Nutzung architetkonischer Möglichkeiten von Prozessoren und Rechnersystemen
			\item Für den Software-Entwuf existieren eine Vielzahl von Werkzeugen
		\end{itemize}
		\item Software-Ergonomie
		\begin{itemize}
			\item Gesamtheit der Krieterien für eine Nutzerakzeptanz
			\item Software für die Gestaltung der Beutzerschnittstelle ist oft umfangreicher als die Applikationssoftware
		\end{itemize}
		\item Algorithmen-Entwurf
		\begin{itemize}
			\item Optimale Programme erfordern geeignete Lösungsalgorithmen
			\item Besonders drastische Bedingungen bestehen bei Parallelverarbeitung durch erforderliche Parallelalgorithmen und Parallelisierung sequenzieller Algorithmen
			\item Optimale Parallelalgorithmen können zum Einsatz sogenannter Systolischer Arrays führen
		\end{itemize}
	\end{itemize}
\end{itemize}
\subsection{Entwurf eines Rechnersystems}
\begin{itemize}
	\item Kompromissfindung zwischen
	\begin{itemize}
		\item Zielsetzungen: Anwendungsbereiche, Funtkionalität, Verfügbarkeit, ...
		\item Gestaltungsgrundsätzen: Modularität, Sparksamkeit, Fehlertoleranz, ...
		\item Randbedingungen: Technologie, Finanzen, Umwelt, ...
	\end{itemize}
	\item Zielsetzungen
	\begin{itemize}
		\item Andwendungsbereich
		\begin{itemize}
			\item Technisch-wissenschaftlicher Bereich (z.B. Strömungsmechanik, Materialforschung, ...)
			\item Kommerzieller Bereich (z.B.: Datenbankanwendungen, Internet, Suchmaschinen,...
			\item Eingebettete Systeme (z.B.: Verarbeitung digitaler Medien, Automatisierungstechnik, ...)
		\end{itemize}
		\item Benutzerfreundlichkeit
		\begin{itemize}
			\item Beziehung zwischen einem Rechnersystem und Nutzer
			\item Gestaltung der Schnittstelle zwischen dem Rechnersystem und seinem Benutzer
		\end{itemize}
		\item Verlässlichkeit/Robustheit
		\begin{itemize}
			\item Gewährleistung einer minimalen Verfügbarkeit des Systems
		\end{itemize}
		\item Erweiterbarkeit/Skalierbarkeit
		\begin{itemize}
			\item Eine Rechnerfamilie ist in Ausbaustufen skalierbar für verschiedene Anwendungen
			\item Skalierbarkeit ist ein wesentliches Erfordernis aller Rechnersysteme \\ \(\Rightarrow\) Chancen auf dem Markt
			\item z.B. SGI Slogan: Paying by growing von Einstiegs-Servern bis zu HPC-Maschinen
			\item Motivation: Architektur kennen und schätzen lernen \(\Rightarrow\) Ideen für neue Projekte
			\item Fragestellung: Welche architektonischen Voraussetzungen sind für die Erweiterbarkeit erforderlich?
		\end{itemize}
		\item  Konsistenz
		\begin{itemize}
			\item Eigenschaft des Systems mit folgerichtigem, schlüssigem Aufbau
			\item Vorausschauender Entwurf einer Rechner- bzw. Prozessorarchitektur, der zu erwartenden Architekturerweiterungen schon Rechnung trägt
			\item Beispiel: MIPS-Prozessor-Familie
		\end{itemize}
		\item Orthogonalität/Modularität
		\begin{itemize}
			\item Funtkional unabhägige Teilelmente sind unabhängig voneinander spezifiziert und realisiert
			\item Standardisierung hat immer größere Bedeutung 
			\item Hauseigene Lösungen ohne Zweitanbieter relativ chancenlos
			\item Wichtiger Gestaltungsgrundsatz für Befehlssätze \(\Rightarrow\) vereinfachte Code- \\Erzeugung in Compilern
		\end{itemize}
	\end{itemize}
	\item Gestaltungsgrundsätze
	\begin{itemize}
		\item Symmetrie
		\item Angemessenheit
		\item Sparsamkeit
		\item Wiederverwendbarkeit
		\item Transparenz/Abstraktion
		\item Virtualität
	\end{itemize}
	\item Randbedingungen
	\begin{itemize}
		\item Technologische
		\item Finanzielle
		\item Käuferakzeptanz
		\item Moore's Law
	\end{itemize}
\end{itemize}
\subsection{Architectural Trends}
\begin{itemize}
	\item Architecture translates technology's gifts into performance and capability
	\item Resolves the tradeoff between parallelism and locality
	\item Understanding microprocessor architectural trends
	\item Greatest trend in VLSI generation is increase in parallelism
	\begin{itemize}
		\item up to 1985: bit level parallelism: 4-bit \(\to\) 8-bit \(\to\) 16-bit
		\item mid 80s to mid 90s: instruction level parallelism
		\item End 90s: thread level parallelism and/or chip multiprocessors
		\item Next step: reconfigurable computing
	\end{itemize}
	\item How far will ILP go? 
	\begin{itemize}
		\item Infinite resources and fetch bandwidth, perferct branch prediction and renaming
	\end{itemize}
	\item Thread Level Parallelism "on board"
	\begin{itemize}
		\item Micro on a chip makes it natual to connect many to shared memory
	\end{itemize}
	\item Problem: Prozessor-Memory Performance Gap: 50 percent per year
\end{itemize}
\subsection{Bemerkungen zum klassischen Digitalrechner}
\begin{itemize}
	\item zentrale Steuerung durch Steuerwerk
	\item zentrale Verarbeitung durch Rechenwerk
	\item Harvard \(\leftrightarrow\) von Neumann
	\item Harvard-Architektur
	\begin{itemize}
		\item Vorteile
		\begin{itemize}
			\item geringere Wartezeiten
			\item einfache Busverwaltung
		\end{itemize}
		\item Nachteile
		\begin{itemize}
			\item höherer Verdrahtungsaufwand (hohe Kabelkosten)
			\item verminderte Flexibilität bei der Ausnutzung der Speicher (keine Austauschbarkeit)
		\end{itemize}
		\item Grundidee: Optimierung der Speicherhierarchie
	\end{itemize}
	\item Von-Neumann-Architektur
	\begin{itemize}
		\item Architektur des minimalen Hardware-Aufwands
		\item Einzigartige Verbindung von
		\begin{itemize}
			\item Einfachheit
			\item Flexibilität
		\end{itemize}
		\item Grundelemente
		\begin{itemize}
			\item Leitwerk und Rechenwerk
			\item Hauptspeicher
			\item Eingabeeinheit und Ausgabeeinheit
			\item Verbindungseinrichtung
		\end{itemize}
		\item Vorteile
		\begin{itemize}
			\item Einfachheit
			\item maximale Flexibilität
		\end{itemize}
		\item Nachteile
		\begin{itemize}
			\item Befehle und Programmdaten müssen über einen Kanal zwischen \\Speicher und Prozessor transportiert werden (sog. physikalischer von- \\Neumann-Flaschenhals)
			\item streng sequentielle Abarbeitung (sog. intellektueller von-\\Neumann-Flaschenhals)
			\item große semantsiche Lücke zwischen den für die Benutzungsschnittstelle typischen höheren Programmiersprachen und den im von-Neumann-Speicher enthaltenen von-Neumann-Variablen
		\end{itemize}
	\end{itemize}
\end{itemize}
\subsection{Aufgaben und Ziele der Rechnerarchitektur}
\subsubsection{Aufgaben}
\begin{itemize}
	\item Architekturanalyse bestehender Rechnersysteme und ihrer Komponenten, wie Prozessoren, Speicher, Verbindungseinrichtungen u.a.
	\item Beobachtung der Evolution von Rechnerfamilien und Architekturklassen sowie Ableitung neuer Architekturrichtungen 
	\item Entwurf und Synthese neuer leistungsfähiger Rechensysteme mit bewährten Entwurfsmethoden und automatisierten Werkzeugen
	\item Umsetzung von Leistungsanforderungen, die von Anwendungsbereichen vorgegeben werden, in Struktur und Organisationsformen für Rechner und deren Komponenten
\end{itemize}
\subsubsection{Ziele}
\begin{itemize}
	\item Leistungssteigerung durch Architekturverbesserungen
	\item Steigerung der Nutzerakzeptanz durch benutzergerechte System- und Anwendersoftware
	\item Entwurf ausbaufähiger Rechnerarchitekturen, die konkurrenzfähig bleiben und Weiterentwicklungen mit reduzierten Kosten gestatten
\end{itemize}
\subsection{Klassifizierung nach Flynn}
\begin{itemize}
\item SISD - single instruction stream, single data stream
\item SIMD - single instruction stream, multiple data streams
\item MISD - multiple instruction streams, single data stream
\item MIMD - multiple instruction streams, multiple data streams
\end{itemize}

\section{Intel Prozessoren}
\subsection{Ursprung}
\begin{itemize}
	\item 32-Bit Integer-Verarbeitungsbreite
	\item CISC Befehlssatz
	\begin{itemize}
		\item Vairable Befehlslänge
		\item Arithmetische Operationen mit Speicheradressen
		\item 32-Bit Immediate Werte im Befehlswort
		\item 1-Adress und 2-Adress Format
	\end{itemize}
	\item SISD
	\item Virtueller Speicher
\end{itemize}
\subsection{Intel 80386}
\subsubsection{IA-32 Register}
\begin{itemize}
		\item EIP: Instruction Pointer
		\item EFLAGS
		\begin{itemize}
			\item Overflow-, sign-, zero- Flag
			\item Für Verzweigungsbefehle
		\end{itemize}
		\item 8 General Purpose Register
		\begin{itemize}
			\item Häufig implizite Adressierung
		\end{itemize}
		\item Segment Register zur Speicheradressierung
\end{itemize}
\subsubsection{Stack}
\begin{itemize}
	\item Wegen geringer Registerzahl häufiges Ausweichen auf Speicher erforderlich
	\item Stack ist spezieller Speicherbereich in dem Werte zwischengespeichert werden
\end{itemize}
\subsubsection{Adressierungsarten}
\begin{itemize}
	\item Immediate Operand
	\item Immediate Adresse
	\item Register Zugriff
	\item Register Indirekt
	\item Register indirekt mit displacement
	\item Zugriffe auf Stack (push/pop)
	\begin{itemize}
		\item Register indirekt mit preautodecrement
		\item Register indirekt mit postautoincrement
	\end{itemize}
	\item Implizite Adressierung
	\begin{itemize}
		\item Feste Quell- oer Zielregister für Befehle z.B.:
		\begin{itemize}
			\item ein operand in EAX
			\item Loop Counter in ECX
			\item ESP/EBP/ESI/EDI für Adressberechnung
		\end{itemize}
		\item spart Bits im Befehl
	\end{itemize}
	\item Speicher indirekt
\end{itemize}
\subsubsection{Virtueller Speicher}
\begin{itemize}
	\item Mehrere Programme teilen sich den physischen Speicher
	\item Eigener virtueller Adressraum für jedes Programm
	\begin{itemize}
		\item Adressierungsarten beziehen sich auf virtuelle Adressen
		\item Übersetzung in physische Adressen erfolgt zusätzlich
	\end{itemize}
	\item Ressourcenverwaltung durch Betriebssystem
\end{itemize}
\subsection{Intel 80486}
\begin{itemize}
	\item Integrierter L1-Cache
	\item Integrierte FPU )486DX
\end{itemize}
\subsubsection{Cache}
\begin{itemize}
	\item Kleiner, schneller Zwischenspeicher
	\item Puffer für häufig benötigte Daten und Befehle
\end{itemize}
\subsubsection{Pipelining}
\begin{itemize}
	\item Aufteilung der Befehlsverarbeitung in 5 Phasen
	\begin{itemize}
		\item Instruction Fetch (IF): Befehl laden
		\item Decode1 (D1)
		\item Decode2 (D2)
		\item Execute (EX)
		\item  ...
	\end{itemize}
	\item Mehrere Befehle gleichzeitig in Bearbeitung
	\item Speedup durch Pipelining
	\begin{itemize}
		\item ermöglicht höhere Taktfrequenz
		\item nach Anlaufphase wird ein Befehl pro Takt fertiggestellt
	\end{itemize}
\end{itemize}
\subsection{Pentium}
\begin{itemize}
	\item Getrennte L1-Caches; 8KB für Instruktionen; 8KB für Daten
	\item Zwei Befehle gleichzeitig in jeder Phase \\ \(\to\) Es werden zwei Befehle pro Takt fertiggestellt
	\item 2. Pipeline nur für einfache Befehle
\end{itemize}
\subsection{Pentium MMX}
\begin{itemize}
	\item Erweiterung der ISA um SIMD Befehle
	\item 8 64-Bit Register
	\begin{itemize}
		\item Abgebildet auf FPU Register
	\end{itemize}
	\item Nur Integer Befehle
\end{itemize}
\subsection{Pentium Pro}
\begin{itemize}
	\item CISC Befehlssatz hinderlich für effizientes Pipelining
	\begin{itemize}
		\item Variable Ausführungszeit in Ausführungsphase (EX)
		\item Direkte Verarbeitung von Speicheroperanden
		\begin{itemize}
			\item Cache Misses blockeren nachfolgende Befehle
			\item Steigende Speicherlatenz bei höheren Taktraten
		\end{itemize}
		\item \(\Rightarrow\) Durchsatz (instruction per cycle) i.d.R. weit unter theoretischem Maximum
	\end{itemize}
	\item Lösung:
	\begin{itemize}
		\item RISC Verarbeitung in Rechenwerken
		\item Out-of-order Execution zur Verdeckung von Speicherlatenzen
	\end{itemize}
\end{itemize}
\subsubsection{RISC Kern}
\begin{itemize}
	\item Übersetzung der x86 Befehle in internen RISC Befehlssatz (Microops)
	\item Eine Microop für simple Operationen
	\item Mehrere Microops für komplexe Operationen
	\begin{itemize}
		\item Aufspaltung in Speicherzugriff und arithmetische Operation
		\item Trigonometrische Funktionen als Mikroprogramm
	\end{itemize}
\end{itemize}
\subsubsection{Out-of-Order Execution}
\begin{itemize}
	\item Abarbeitung der Microops abweichend von der Programmreihenfolge
	\begin{itemize}
		\item Scheduler (Reservation Station)
		\begin{itemize}
			\item Sendet Microops an die Rechenwerke sobald Operanden verfügbar sind
			\item Microops einer Instruktion müssen nicht zusammen abgearbeitet werden
		\end{itemize}
		\item Reorder Buffer (ROB)
		\begin{itemize}
			\item Zusätzliche Register zur Speicherung der Ergebnisse (Register Renaming)
			\item Zustand der für Software sichtbaren Register wird in Programmreihenfolge aktualisiert (In-order completion)
		\end{itemize}
	\end{itemize}
\end{itemize}
\subsection{Pentium 2 / Pentium 3}
\begin{itemize}
	\item Weiterentwicklung des PPentium Pro
	\begin{itemize}
		\item 3-fach superskalar
		\item 2x 16KB L1-Cache
		\item Zunächst Slot Prozessoren mit L2-Cache in zweitem Chip
		\item später mit on-die L2-Cache wieder in Sockelbauweise
	\end{itemize}
	\item Pentium 3 mit SSE
\end{itemize}
\subsubsection{Streaming SIMD Extensions (SSE)}
\begin{itemize}
	\item Register FILL?
	\item Datentypen FILL?
\end{itemize}
\subsection{Pentium 4}
\begin{itemize}
	\item Designziel hohe Taktfrequenz
	\begin{itemize}
		\item Frequenz begrenzt durch Länge der Pipelinestufen
		\item Extrem lange Pipeline durch wetieres Aufteilen der einzelnen Phasen
		\begin{itemize}
			\item erste Modelle mit 20 Stufen, später 31 (vgl. Pentium 3: 10 Stufen)
		\end{itemize}
		\item 2006 eingestellt, da hohe Frequenzen u hohem Stromverbrauch führten
	\end{itemize}
	\item Execution Trace Cache
	\begin{itemize}
		\item Kein gewöhnlicher L1 Instruction Cache
		\item Speicherung bereits dekodierter Instruktionen
	\end{itemize}
	\item HyperThreading
	\begin{itemize}
		\item Betriebssystem sieht zwei logische Prozessoren pro CPU
		\item Doppelte Registersätze, gemeinsame Nutzung der Rechenwerke
	\end{itemize}
	\item Befehlssatzerweiterungen: SSE2, ab 2004 SSE3
\end{itemize}
\subsubsection{Netburst Mikroarchitektur}
\begin{itemize}
	\item Geringe Decoder Leistung
	\begin{itemize}
		\item bei Misses im Trace Cache nur 1 Microop pro Takt
	\end{itemize}
	\item 64 Bit breite SIMD Einheiten
	\begin{itemize}
		\item SSE Befehle in 2 Operationen
	\end{itemize}
	\item 126 Microops ROB
	\item 2 Integer ALUs
	\item 2 FP Einheiten
	\item L1 Cache pro Kern
	\begin{itemize}
		\item 128 Bit lesen/schreiben pro Takt
	\end{itemize}
	\item Hyperthreading
	\begin{itemize}
		\item 2 Threads gleichzeitig
	\end{itemize}
\end{itemize}
\subsubsection{SSE Erweiterungen}
\begin{itemize}
	\item SSE 2
	\begin{itemize}
		\item 64-Bit Floating Point Befehle (double precision)
		\item 2 Operationen pro Befehl
	\end{itemize}
	\item SSE 3
	\begin{itemize}
		\item Mehrere Operanden aus einem Register
		\item Reduziert Kopieroperationen
	\end{itemize}
\end{itemize}
\subsection{Pentium M/ Core Solo/ Core Duo}
\begin{itemize}
	\item Parallelentwicklung zu Pentium 4
	\item Basieren auf Pentium 3
	\item Energiesparende Architektur für Mobilrechner
	\begin{itemize}
		\item Speedstep Technologie
		\begin{itemize}
			\item Anpassung der Taktfrequenz an Auslastung
			\item Reduziert Leistungsaufnahme während Programme ausgeführt werden
		\end{itemize}
		\item Clock Gating
		\begin{itemize}
			\item Trennung von Logikblöcken vom Taktsignal
			\item Reduziert Leistungsaufnahme in Leerlaufphasen
		\end{itemize}
	\end{itemize}
\end{itemize}
\subsection{Intel64 Prozessoren (Auswahl)}
\begin{itemize}
	\item 2004 Pentium 3 /Pentium D
	\item 2006 Core2 Duo, Core2Quad, Xeon54xx
	\item 2008 Core i5/i7, Xeon 55xx (Nehalem)
	\item 2010 Core i3/i5/i7, Xeon 56xx (Westmere)
	\item 2011 2.Gen i3/5/7, Xeon E3 (Sandy Bridge)
	\begin{itemize}
		\item integrierte GPU
		\item Advanced Vector Extansions (AVX)
	\end{itemize}
	\item 2012 3.Gen, Xeon E3 v2 (Ivy Bridge)
	\item 2013 4.Gen, Xeon E3 v3 (Haswell)
\end{itemize}
\subsubsection{Befehlssatz}
\begin{itemize}
	\item IA-32 Befehlssatz auf 64 Bit Verarbetungsbreite erweitert
	\item Registeranzahl verdoppelt
	\begin{itemize}
		\item Weniger Stackzugriffe nötig
		\item Erhöhte Codegröße
	\end{itemize}
	\item Größerer virtueller Adressraum
\end{itemize}
\subsection{Multicore Prozessoren}
\begin{itemize}
	\item Moores Law
	\item Leistung einzelner Prozessoren nicht beliebig steigerbar
	\begin{itemize}
		\item Höhere Grade an Superskalarität erhöhen Rechenleistung nicht proportional aufgrund von Abhängigkeiten zwischen Befehlen
		\item Leistungssteigerungen durch Pipelining begrenzt durch Verzweigungen im Code
	\end{itemize}
	\item Multi-Core Prozessoren
	\begin{itemize}
		\item Leistungssteigerung durch Duplikation von Teilen des Prozessors
		\item Erfordert Anpassung der Software an Nutzung mehrerer Kerne
	\end{itemize}
\end{itemize}
\subsubsection{Entwicklung des Energieverbrauchs}
\begin{itemize}
	\item Kühlung limitert Verbrauch pro Prozessor
	\item Mehr Kerne mit weniger Frequenz sind effizienter für parallele Anwendungen
\end{itemize}
\subsection{Intel Core Microarchitektur Core2Duo}
\begin{itemize}
	\item Decodiert bis zu 4 Instruktionen pro Takt (5 mit Makroop-Fusion)
	\item 128 Bit breite SIMD Einheiten 
	\item 96 Microops ROB
	\item Verarbeitung von bis zu 6 Microops gleichzeitig
	\item L1-Cache pro Kern
	\item L2-Cache und FSB von beiden Kernen genutzt
\end{itemize}
\subsection{Intel Nehalem Mikroarchitektur}
\begin{itemize}
	\item Prozessorkerne kaum verändert gegenüber Core Mikroarchtektur
	\begin{itemize}
		\item SSE 4.2
		\item Hyperthreading
	\end{itemize}
	\item L2-Cache pro Kern
	\item Gemeinsamer L4-Cache für alle Cores
	\item Integrierter Speichercontroller
	\item FSB ersetzt durch Intel QuickPath Interconnect
\end{itemize}
\section{fill 03.05.16}
\section{}
\subsection{Intel Itanium}
Intel Itanium 2 1.5GHz, Fortran/C \\
Tabelle siehe Folien
\subsubsection{Quad-Core Itanium} 
\begin{itemize}
	\item Bereiche mit unterschiedlicher Taktrfrequenz und Spannung
	\item 6MB L3 pro Kern
	\item QPI-Links zur Verbindung mit anderen Prozessoren (Statt FSB)
	\item On-chip Speichercontroller
\end{itemize}
\subsubsection{8-core Itanium}
\begin{itemize}
	\item Gemeinsamer L3 Cache für alle Kerne
	\item Neue Mikroarchitektur für höhere IPC
	\begin{itemize}
		\item Fetch und Decode: 6 Instruktionen pro Takt (2 Befehls-Gruppen)
		\item Execution: 12 Instruktionen pro Takt (unabhängig von Gruppen)
	\end{itemize}
\end{itemize}
\subsection{IBM Power}
\subsubsection{Die Power Architektur}
POWER: Performance Optimization With Enhanced RISC
\begin{itemize}
	\item[90] IBM POWER1
	\item[93] IBM POWER2
	\item[96] IBM POWER2 Superchip (P2SC)
	\item[93] Einführung der PowerPC-Prozessoren
	\item[98] Einführung der IBM POWER3-Prozessoren
	\item[01] Einführung des IBM POWER4-Prozessors
	\item[04] POWER5
	\item[07] POWER6
	\item[10] POWER7
	\item[14] POWER8
\end{itemize}
\subsubsection{POWER4+ Processor}
\begin{itemize}
	\item 2 Cores pro Chip
	\item Pro Core l1 D-Cache und L1-l-Cache
	\item Shared L2-Cache
	\item L3-Cache off chip
	\item 2 FPUs pro Core
	\item Fused-Multiply-Add
	\item 6,8 GFLOPS@1,7GHz
\end{itemize}
\subsubsection{Speicher  IO-Bandbreite}
Grafik siehe Folien
\subsubsection{8Prozessor SMP System(MCM: 11x11cm}
Grafik siehe FOlien
\subsubsection{Mikroarchitektur des Proessors IBM POWER4}
\begin{itemize}
	\item Jeder iBM POWER4-Chip besitzt zwei 64-Bit-Mikroprozessorkerne
	\item Der gemeinsam genutzte L2-Cache ist in 4 gleichgroße Teile mit jeweils einem speraten L2-Cache-Controller aufgeteilt
	\item Das L3-Cache-Directory und der L3-Cache-Controller befindensich auf dem Chip während der L3-Cache selbst aus DRAM besteht
	\item Der für die I/O-Operationen verantwortliche GX-Controller ist mit zwei, je einer Richtung zugeordneten 4-Byte-breiten GX-Bussen ausgestattet
	\item Fabric-Controller
	\item Der Mikroprozessorkern ist n Form einer typisch superskalaren Mikroarchitektur implementiert
	\item 8 unahängige Funktionseinheiten, die nebenläufig parallel arbeiten können
	\item Jede der FPUs ist in der Lage einen Multiply/Add-Befehl pro Takt fertigzustellen
\end{itemize}
\subsubsection{Befehlsausführung und Ressourcnverwaltung}
\begin{itemize}
	\item Der IBM POWER4 arbeitet mit spekulativer Befehlsausführund, d.h. Befehle werden ausgeführt bevor sicher ist, ob sie überhaupt benötigt werden
	\item Zur Vermeidung von Pseudoabhängigkeiten durch out-of-order Processing wird mit Register-Renaming gearbeitet
\end{itemize}
\subsubsection{Pipeline}
Grafik siehe Folien
\subsubsection{Instruction Fetch, Group Formation und Dispatch 1}
\begin{itemize}
	\item Die Adresse für den L1-I-Cache-Zugriff steht im Insturction Fetch Adress Register. Die adressinformation erhält das IFAR von der BR-Logik
	\item In der IF-Phase werden die Befehle aus dem L1-Cache geholt und in die Instruction-Queue geladen. Die I-Queue ermöglicht dabei die Fortsetzung des Pipelinings auch bei einem Cache-Miss
	\item Die geholten Befehle werden nach Sprugbefehlen durchsucht
	\item In den Phasen Dß bis GD werden die Befehle decodert, zerlegt, zu gruppen formatiert
	\item ...
\end{itemize}
\subsubsection{Out-of-Order Processing}
\subsubsection{Load/stor Istruction Processing }
\subsubsection{Floating-Point Execution Pipeline}
\subsubsection{Group Completion}
\begin{itemize}
	\item Eine Befehlsgruppe wird beendet, wenn die Ergebnisse in das Zielregister geschrieben wurde und die Ergebnisse somit für das weitere Programm verfügbar sind.
	\item Wurde ein Befehl oder eine Befehlsgruppe spekulativ ausgeführt kann sie erst vollendet werden, falls alle Bedingungen für seine Ausführung erfolgreich waren
	\item Eine Befehlsgruppe kann erst vollendet werden, wenn alle älteren Gruppen komplett und korrekt abgeschlossen wurden
	\item Por Takt ist eine Befehlsgruppe komplettierbar
\end{itemize}
\subsubsection{Matrix Multiplication}
Grafik siehe Folien
\subsection{POWER7}
\begin{itemize}
	\item 32MB shared L3-Cache; eDRAM
	\item unterschiedliche SRAM Zellen für L1- und L2-Cache
	\item 4 Threads pro Kern
	\item Local (MCM) und Remote SMP Interface
	
\end{itemize}
\subsubsection{SMP System}
\begin{itemize}
	\item 4 Chips pro MCM
	\item 8 MCMs können direkt verbunden werden
	\begin{itemize}
		\item 256 Kerne; 1024 Threads
	\end{itemize}
\end{itemize}
\subsubsection{POWER Prozessorfamilie}
Grafik siehe Folien
\subsection{MIPS}
\subsubsection{MIPS Prozessoren}
\begin{itemize}
	\item[81] MIPS RISC ISA gegründet
	\item[84] Gründung MIPS
	\item[85] erster kommerzieller RISC-CHIP: MIPS R2000
	\item[88] R3000
	\item[91] R4000
	\item[94] R8000
	\item[96] R5000
	\item[96] R10000
	\item[98] R12000
	\item[02] R16000
\end{itemize}
\subsubsection{R10k}
\begin{itemize}
	\item Ab dem Befehlsatz MIPS III werden folgende Datenregister auf ISA-Ebene unterstützt
	\begin{itemize}
		\item 32 General Purpose Register zu je 64Bit
		\item 32 FLoating Point Register zu je 64Bit
	\end{itemize}
	\item Ab MIPS I werden folgende Adressierungsarten unterstützt:
	\begin{itemize}
		\item Direktwert-A
		\item Direkte Register-A
		\item PC-relative A
		\item Relative Hauptspeicheradresssierung über ein Register mit Displacement
	\end{itemize}
	\item Ab MIPS IV gib es im beschränkten Umfang indexierte A
\end{itemize}
\subsubsection{Befehlssätze der Prozessoren R10k und R12k}
\subsubsection{ALU-Befehle}
\subsubsection{Mikroarchitektur der Prozessoren R10k und R12k}
\subsubsection{Pipelines des MIPS R10k}
\begin{itemize}
	\item Der superskalare R10k arbeitet mit 5 weitestgehend unabhängigen Pipelines und ebso vielen Ausführungseinheiten
	\item Für jeden Operationstyp steht eine Warteschlange für Befehle zur Verfügung
	\item Die Load/Store-Warteschlange ist FIFO-georndet, um Speicherabhängigkeiten und Datenkonsistenz zu gewährleisten
	\item Die anderen beiden Warteschlangen sind keiner strengen Ordnung unterworfen
\end{itemize}
\subsubsection{Pipeline-Stufen 3 bis 7}
\subsubsection{Floating Point Units}
\begin{itemize}
	\item Floating-Point-Multiplizierer
	\item Floating-Point-Dividierer und Radizierer
	\item Floating-Point Addierer
\end{itemize}
\subsubsection{Integer Units und Load/Store Unit}
\begin{itemize}
	\item Integer-Einheit 1
	\item Integer-Einheit 2
	\item Load/Store
\end{itemize}
\subsubsection{Godson-3}
\begin{itemize}
	\item Basis für chinesisches Supercomputer Programm
	\item 4-fach superskalar mit out-of-order Execution
	\item MIPS64 ISA mit Erwetierung für x86 Emulation
	\item Quad-Core Design
	\begin{itemize}
		\item On-chip Speichercontroller
		\item HyperTransprot zur Kommunikation mit chipsatz und anderen Prozessoren
	\end{itemize}
\end{itemize}
\subsection{SPARC}
\begin{itemize}
	\item[82] Wesentliche Forschungsarbeiten an der University of California Berkeley auf dem Gebiet von RISC-Prozesorarchitekturen
	\item[87] Sun Microsystems stellt die SPARC-Architektur vor: Scalable Processor Architecture
	\item[90] erste 32-Bit Implementierung
	\item[95] SPARC64/UltraSparc mit 64-Bit Verarbeitungsbreite
	\item[05] UltraSparc T1
	\item[07] UltraSpard T2
	\item[09] Sparc64 VIIIfx
	\item[10] Sparc T3: 16 Kerne, 8fach SMT
\end{itemize}
\subsubsection{SUN Niagara II (T2)}
\begin{itemize}
	\item 8 Prozessorkerne
	\item 4 MB L2-Cache
	\item Max. 16 DDR2 FB-DIMMs
	\item 2-mal 10Gb/s Netzwerk
	\item x8 PCI-Express
\end{itemize}
\subsubsection{T2 Multithreading}
\begin{itemize}
	\item Abwechelndes Arbeiten an mehreren Threads, um Speicherlatenz (Cahcelatenz zu verdecken
	\begin{itemize}
		\item Kein komplexes out-of-order Design erforderlich
		\item Erforder hohes Maß an Parallelität in der Software
	\end{itemize}
	\item Abwechselndes Arbeiten an mehreren Threads um Speicherlatenz zu verdecken
\end{itemize}
\subsection{CELL Broadband Engine}
\begin{itemize}
	\item Heterogener Multi-Core
	\begin{itemize}
		\item 1 PowerPC Kern (PPE)
		\item 8 Synergistic Processing Elemts (SPE)
	\end{itemize}
	\item SPE:
	\begin{itemize}
		\item In-order Execution
		\item 4 single precision Operationen pro Takt
		\item Kein Cache
		\item 256 KB Local Store
	\end{itemize}
	\item Gemeischaftsentwicklung von IBM, Sony und Toshiba
	\item PowerXCell 8i
	\item Roadrunner
	\begin{itemize}
		\item Erster PetaFlop Rechner
		\item 3060 hybride Knoten
	\end{itemize}
\end{itemize}
\subsection{ARM}
\begin{itemize}
	\item ARM: Advanced RISC Machines
	\item IP-Cores zur Integration in System-on-Chips
	\item 32-Bit RISC Architektur
	\item Zeichnen sich durch geringen Stromverbrauch aus
	\item Häufige Verzweigungen schlecht für effizientes Pipelining
	\item Paralleles Ausführen beider Pfade bei if-then-else
	\item Einsatz: unterschiedliche Kerne mit gleichem Befehlssatz
	\item Cortes A15 liefert doppelte bis dreifache Rechenleistung des Cortex A7
	\item Cortex A7 hat drei- bis vierfache Rechenleistung pro Watt
\end{itemize}
\subsection{DEC ALPHA}
\begin{itemize}
	\item Alpha 21064 und 21164 in Supercomputern on Cray
	\item 2004 nach Übernahme durch HP eingestellt
	\item 64 Bit RISC Architektur
\end{itemize}