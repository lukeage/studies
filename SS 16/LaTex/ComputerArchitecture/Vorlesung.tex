%!TEX root = ../head.tex

\chapter{Vorlesung}
\section{Einführung}

\subsection{Big Data}
"Big Data hat die Chance die geistige Mittelschicht in Hartz IV zu bringen"

\section{Vorlesung}
\subsection{ZIH}
\begin{itemize}
	\item HAEC
	\item CRESTA Perfomrance optimization
	\item MPI correctness checking: MUST
	\item Architecture of the new system (HRSK-II)
\end{itemize}
\subsection{Begriffe und Definitionen}
\begin{itemize}
	\item Der Begriff Rechnerarchitektur wurde von dem englischsprachigen Begriff computer architecture abgeleitet
	\item Computer architecture ist eine Teildisziplin des Wissenschaftsgebietes computer enginering, welches die überwiegend ingeniermäßige Herangehensweise beim Entwurf und der Optimierung von Rechnersystemen deutlich zum Ausdruck bringt.
	\item Zwei Deutungen des englischen Begriffs "Architecture"
	\item Zur Definition der Rechnerarchitektur
	\begin{itemize}
		\item Architektur: Ausdruck insbesondere der Möglichkeiten der Programmierschnittstelle
		\begin{itemize}
			\item Maschinenbefehlssatz
			\item Registerstruktur
			\item Adressierungsmodi
			\item Unterbrechungsbehandlung
			\item Ein- und Ausgabe-Funktionalität
		\end{itemize}
		\item Komponenten / Begriffsbildung
		\begin{itemize}
			\item Hardwarestruktur
			\item Informationsstruktur (Maschinendatentypen)
			\item Steuerungsstruktur
			\item Operationsprinzip
		\end{itemize}
	\end{itemize}
	\item Taxonomie
	\item Dreiphasenmodell zum Entwurf eins Rechnersystems
	\begin{itemize}
		\item Bottom-up (Realisierung \(\to\) Implementierung \(\to\) Rechnerarchitektur)
		\item Top-down (Rechnerarchitektur \(\to\) Implementierung \(\to\) Realisierung)
		\item Rückwirkungen durch den technologischen Stand						\end{itemize}
\end{itemize}

\section{VL}
\subsection{Modifiziertes Dreiphasenmodell zum Entwurf eines RS}
\subsubsection{Befelhlssatzarchitektur}
\subsubsection{Implementierung}
\subsubsection{Realisierung}
\subsection{Architektur-Definition (Tanenbaum)}
Den Satz von Datentypen, Operationen und Merkmalen jeder Ebene bezeichnet man als ihre Architektur. Die Architektur betrifft die Aspekte, die für den Benutzer der jeweiligen Ebene sichtbar sind.
\subsection{Architektur-Definition (Hennessy/Patterson)}
We use the term instruction set architecture (ISA) to refer to the actual programmervisible instruction set in this book. the ISA serves as the boundary betweeen the software and hardware. \\ The implementation of a computer has two components: organization and hardware.
\subsection{Einflusskomplexe}
\begin{itemize}
	\item Die Rechnerarchitektur steht in Wechselwirkung mit zahlreichen benachbarten Disziplinen
	\begin{itemize}
		\item Betriebssysteme
		\begin{itemize}
			\item Konzepte aus dem Bereich Betriebssysteme werden durch Rechnerkomponenten unterstützt (z.B.: Virtueller Speicher/ I/O-Instruktionen)
			\item Andererseits werden durch moderne Rechnerarchitektur-Konzepte neue Anforderungen and die Betriebssysteme gestellt (z.B.: Erweiterung für Parallelarbeit)
		\end{itemize}
		\item Topologie
		\begin{itemize}
			\item Ursprünglich Teilgebiet der Mathematik zur Untersuchung der Struktur von Punktmengen und Räumen einschließlich ihrer Klassifizierung
			\item Daraus folgte: Gestaltung von Verbindungseinrichtungen in Multiprozessorsystemen (3-D Hypercube, D-Gitter)
		\end{itemize}
		\item Hardware-Entwurf
		\begin{itemize}
			\item Die Sammlung von Anforderungen bildet die strukturelle und organisatorische Entwurfsspezifikation der Teilkomponenten eines Rechners
			\item Darstellung: Very-High-Scale-Hardware-Description-Language (VHDL)
		\end{itemize}
		\item Compilerbau und Softwaretechnik
		\begin{itemize}
		\item Codegenerator eines Compilers hänt von Architektur und Befehlssatz des Zielprozessors ab.
			\item Intel-Titanium-Prozessor: EPIC-Architektur
		\end{itemize}
		\item Software-Entwurf
		\begin{itemize}
			\item Nutzung unterschiedlicher Programmierparadigmen und -modelle zur bestmöglichen Nutzung architetkonischer Möglichkeiten von Prozessoren und Rechnersystemen
			\item Für den Software-Entwuf existieren eine Vielzahl von Werkzeugen
		\end{itemize}
		\item Software-Ergonomie
		\begin{itemize}
			\item Gesamtheit der Krieterien für eine Nutzerakzeptanz
			\item Software für die Gestaltung der Beutzerschnittstelle ist oft umfangreicher als die Applikationssoftware
		\end{itemize}
		\item Algorithmen-Entwurf
		\begin{itemize}
			\item Optimale Programme erfordern geeignete Lösungsalgorithmen
			\item Besonders drastische Bedingungen bestehen bei Parallelverarbeitung durch erforderliche Parallelalgorithmen und Parallelisierung sequenzieller Algorithmen
			\item Optimale Parallelalgorithmen können zum Einsatz sogenannter Systolischer Arrays führen
		\end{itemize}
	\end{itemize}
\end{itemize}
\subsection{Entwurf eines Rechnersystems}
\begin{itemize}
	\item Kompromissfindung zwischen
	\begin{itemize}
		\item Zielsetzungen: Anwendungsbereiche, Funtkionalität, Verfügbarkeit, ...
		\item Gestaltungsgrundsätzen: Modularität, Sparksamkeit, Fehlertoleranz, ...
		\item Randbedingungen: Technologie, Finanzen, Umwelt, ...
	\end{itemize}
	\item Zielsetzungen
	\begin{itemize}
		\item Andwendungsbereich
		\begin{itemize}
			\item Technisch-wissenschaftlicher Bereich (z.B. Strömungsmechanik, Materialforschung, ...)
			\item Kommerzieller Bereich (z.B.: Datenbankanwendungen, Internet, Suchmaschinen,...
			\item Eingebettete Systeme (z.B.: Verarbeitung digitaler Medien, Automatisierungstechnik, ...)
		\end{itemize}
		\item Benutzerfreundlichkeit
		\begin{itemize}
			\item Beziehung zwischen einem Rechnersystem und Nutzer
			\item Gestaltung der Schnittstelle zwischen dem Rechnersystem und seinem Benutzer
		\end{itemize}
		\item Verlässlichkeit/Robustheit
		\begin{itemize}
			\item Gewährleistung einer minimalen Verfügbarkeit des Systems
		\end{itemize}
		\item Erweiterbarkeit/Skalierbarkeit
		\begin{itemize}
			\item Eine Rechnerfamilie ist in Ausbaustufen skalierbar für verschiedene Anwendungen
			\item Skalierbarkeit ist ein wesentliches Erfordernis aller Rechnersysteme \\ \(\Rightarrow\) Chancen auf dem Markt
			\item z.B. SGI Slogan: Paying by growing von Einstiegs-Servern bis zu HPC-Maschinen
			\item Motivation: Architektur kennen und schätzen lernen \(\Rightarrow\) Ideen für neue Projekte
			\item Fragestellung: Welche architektonischen Voraussetzungen sind für die Erweiterbarkeit erforderlich?
		\end{itemize}
		\item  Konsistenz
		\begin{itemize}
			\item Eigenschaft des Systems mit folgerichtigem, schlüssigem Aufbau
			\item Vorausschauender Entwurf einer Rechner- bzw. Prozessorarchitektur, der zu erwartenden Architekturerweiterungen schon Rechnung trägt
			\item Beispiel: MIPS-Prozessor-Familie
		\end{itemize}
		\item Orthogonalität/Modularität
		\begin{itemize}
			\item Funtkional unabhägige Teilelmente sind unabhängig voneinander spezifiziert und realisiert
			\item Standardisierung hat immer größere Bedeutung 
			\item Hauseigene Lösungen ohne Zweitanbieter relativ chancenlos
			\item Wichtiger Gestaltungsgrundsatz für Befehlssätze \(\Rightarrow\) vereinfachte Code- \\Erzeugung in Compilern
		\end{itemize}
	\end{itemize}
	\item Gestaltungsgrundsätze
	\begin{itemize}
		\item Symmetrie
		\item Angemessenheit
		\item Sparsamkeit
		\item Wiederverwendbarkeit
		\item Transparenz/Abstraktion
		\item Virtualität
	\end{itemize}
	\item Randbedingungen
	\begin{itemize}
		\item Technologische
		\item Finanzielle
		\item Käuferakzeptanz
		\item Moore's Law
	\end{itemize}
\end{itemize}
\subsection{Architectural Trends}
\begin{itemize}
	\item Architecture translates technology's gifts into performance and capability
	\item Resolves the tradeoff between parallelism and locality
	\item Understanding microprocessor architectural trends
	\item Greatest trend in VLSI generation is increase in parallelism
	\begin{itemize}
		\item up to 1985: bit level parallelism: 4-bit \(\to\) 8-bit \(\to\) 16-bit
		\item mid 80s to mid 90s: instruction level parallelism
		\item End 90s: thread level parallelism and/or chip multiprocessors
		\item Next step: reconfigurable computing
	\end{itemize}
	\item How far will ILP go? 
	\begin{itemize}
		\item Infinite resources and fetch bandwidth, perferct branch prediction and renaming
	\end{itemize}
	\item Thread Level Parallelism "on board"
	\begin{itemize}
		\item Micro on a chip makes it natual to connect many to shared memory
	\end{itemize}
	\item Problem: Prozessor-Memory Performance Gap: 50 percent per year
\end{itemize}
\subsection{Bemerkungen zum klassischen Digitalrechner}
\begin{itemize}
	\item zentrale Steuerung durch Steuerwerk
	\item zentrale Verarbeitung durch Rechenwerk
	\item Harvard \(\leftrightarrow\) von Neumann
	\item Harvard-Architektur
	\begin{itemize}
		\item Vorteile
		\begin{itemize}
			\item geringere Wartezeiten
			\item einfache Busverwaltung
		\end{itemize}
		\item Nachteile
		\begin{itemize}
			\item höherer Verdrahtungsaufwand (hohe Kabelkosten)
			\item verminderte Flexibilität bei der Ausnutzung der Speicher (keine Austauschbarkeit)
		\end{itemize}
		\item Grundidee: Optimierung der Speicherhierarchie
	\end{itemize}
	\item Von-Neumann-Architektur
	\begin{itemize}
		\item Architektur des minimalen Hardware-Aufwands
		\item Einzigartige Verbindung von
		\begin{itemize}
			\item Einfachheit
			\item Flexibilität
		\end{itemize}
		\item Grundelemente
		\begin{itemize}
			\item Leitwerk und Rechenwerk
			\item Hauptspeicher
			\item Eingabeeinheit und Ausgabeeinheit
			\item Verbindungseinrichtung
		\end{itemize}
		\item Vorteile
		\begin{itemize}
			\item Einfachheit
			\item maximale Flexibilität
		\end{itemize}
		\item Nachteile
		\begin{itemize}
			\item Befehle und Programmdaten müssen über einen Kanal zwischen \\Speicher und Prozessor transportiert werden (sog. physikalischer von- \\Neumann-Flaschenhals)
			\item streng sequentielle Abarbeitung (sog. intellektueller von-\\Neumann-Flaschenhals)
			\item große semantsiche Lücke zwischen den für die Benutzungsschnittstelle typischen höheren Programmiersprachen und den im von-Neumann-Speicher enthaltenen von-Neumann-Variablen
		\end{itemize}
	\end{itemize}
\end{itemize}
\subsection{Aufgaben und Ziele der Rechnerarchitektur}
\subsubsection{Aufgaben}
\begin{itemize}
	\item Architekturanalyse bestehender Rechnersysteme und ihrer Komponenten, wie Prozessoren, Speicher, Verbindungseinrichtungen u.a.
	\item Beobachtung der Evolution von Rechnerfamilien und Architekturklassen sowie Ableitung neuer Architekturrichtungen 
	\item Entwurf und Synthese neuer leistungsfähiger Rechensysteme mit bewährten Entwurfsmethoden und automatisierten Werkzeugen
	\item Umsetzung von Leistungsanforderungen, die von Anwendungsbereichen vorgegeben werden, in Struktur und Organisationsformen für Rechner und deren Komponenten
\end{itemize}
\subsubsection{Ziele}
\begin{itemize}
	\item Leistungssteigerung durch Architekturverbesserungen
	\item Steigerung der Nutzerakzeptanz durch benutzergerechte System- und Anwendersoftware
	\item Entwurf ausbaufähiger Rechnerarchitekturen, die konkurrenzfähig bleiben und Weiterentwicklungen mit reduzierten Kosten gestatten
\end{itemize}
\subsection{Klassifizierung nach Flynn}
\begin{itemize}
\item SISD - single instruction stream, single data stream
\item SIMD - single instruction stream, multiple data streams
\item MISD - multiple instruction streams, single data stream
\item MIMD - multiple instruction streams, multiple data streams
\end{itemize}

\section{Intel Prozessoren}
\subsection{Ursprung}
\begin{itemize}
	\item 32-Bit Integer-Verarbeitungsbreite
	\item CISC Befehlssatz
	\begin{itemize}
		\item Vairable Befehlslänge
		\item Arithmetische Operationen mit Speicheradressen
		\item 32-Bit Immediate Werte im Befehlswort
		\item 1-Adress und 2-Adress Format
	\end{itemize}
	\item SISD
	\item Virtueller Speicher
\end{itemize}
\subsection{Intel 80386}
\subsubsection{IA-32 Register}
\begin{itemize}
		\item EIP: Instruction Pointer
		\item EFLAGS
		\begin{itemize}
			\item Overflow-, sign-, zero- Flag
			\item Für Verzweigungsbefehle
		\end{itemize}
		\item 8 General Purpose Register
		\begin{itemize}
			\item Häufig implizite Adressierung
		\end{itemize}
		\item Segment Register zur Speicheradressierung
\end{itemize}
\subsubsection{Stack}
\begin{itemize}
	\item Wegen geringer Registerzahl häufiges Ausweichen auf Speicher erforderlich
	\item Stack ist spezieller Speicherbereich in dem Werte zwischengespeichert werden
\end{itemize}
\subsubsection{Adressierungsarten}
\begin{itemize}
	\item Immediate Operand
	\item Immediate Adresse
	\item Register Zugriff
	\item Register Indirekt
	\item Register indirekt mit displacement
	\item Zugriffe auf Stack (push/pop)
	\begin{itemize}
		\item Register indirekt mit preautodecrement
		\item Register indirekt mit postautoincrement
	\end{itemize}
	\item Implizite Adressierung
	\begin{itemize}
		\item Feste Quell- oer Zielregister für Befehle z.B.:
		\begin{itemize}
			\item ein operand in EAX
			\item Loop Counter in ECX
			\item ESP/EBP/ESI/EDI für Adressberechnung
		\end{itemize}
		\item spart Bits im Befehl
	\end{itemize}
	\item Speicher indirekt
\end{itemize}
\subsubsection{Virtueller Speicher}
\begin{itemize}
	\item Mehrere Programme teilen sich den physischen Speicher
	\item Eigener virtueller Adressraum für jedes Programm
	\begin{itemize}
		\item Adressierungsarten beziehen sich auf virtuelle Adressen
		\item Übersetzung in physische Adressen erfolgt zusätzlich
	\end{itemize}
	\item Ressourcenverwaltung durch Betriebssystem
\end{itemize}
\subsection{Intel 80486}
\begin{itemize}
	\item Integrierter L1-Cache
	\item Integrierte FPU )486DX
\end{itemize}
\subsubsection{Cache}
\begin{itemize}
	\item Kleiner, schneller Zwischenspeicher
	\item Puffer für häufig benötigte Daten und Befehle
\end{itemize}
\subsubsection{Pipelining}
\begin{itemize}
	\item Aufteilung der Befehlsverarbeitung in 5 Phasen
	\begin{itemize}
		\item Instruction Fetch (IF): Befehl laden
		\item Decode1 (D1)
		\item Decode2 (D2)
		\item Execute (EX)
		\item  ...
	\end{itemize}
	\item Mehrere Befehle gleichzeitig in Bearbeitung
	\item Speedup durch Pipelining
	\begin{itemize}
		\item ermöglicht höhere Taktfrequenz
		\item nach Anlaufphase wird ein Befehl pro Takt fertiggestellt
	\end{itemize}
\end{itemize}
\subsection{Pentium}
\begin{itemize}
	\item Getrennte L1-Caches; 8KB für Instruktionen; 8KB für Daten
	\item Zwei Befehle gleichzeitig in jeder Phase \\ \(\to\) Es werden zwei Befehle pro Takt fertiggestellt
	\item 2. Pipeline nur für einfache Befehle
\end{itemize}
\subsection{Pentium MMX}
\begin{itemize}
	\item Erweiterung der ISA um SIMD Befehle
	\item 8 64-Bit Register
	\begin{itemize}
		\item Abgebildet auf FPU Register
	\end{itemize}
	\item Nur Integer Befehle
\end{itemize}
\subsection{Pentium Pro}
\begin{itemize}
	\item CISC Befehlssatz hinderlich für effizientes Pipelining
	\begin{itemize}
		\item Variable Ausführungszeit in Ausführungsphase (EX)
		\item Direkte Verarbeitung von Speicheroperanden
		\begin{itemize}
			\item Cache Misses blockeren nachfolgende Befehle
			\item Steigende Speicherlatenz bei höheren Taktraten
		\end{itemize}
		\item \(\Rightarrow\) Durchsatz (instruction per cycle) i.d.R. weit unter theoretischem Maximum
	\end{itemize}
	\item Lösung:
	\begin{itemize}
		\item RISC Verarbeitung in Rechenwerken
		\item Out-of-order Execution zur Verdeckung von Speicherlatenzen
	\end{itemize}
\end{itemize}
\subsubsection{RISC Kern}
\begin{itemize}
	\item Übersetzung der x86 Befehle in internen RISC Befehlssatz (Microops)
	\item Eine Microop für simple Operationen
	\item Mehrere Microops für komplexe Operationen
	\begin{itemize}
		\item Aufspaltung in Speicherzugriff und arithmetische Operation
		\item Trigonometrische Funktionen als Mikroprogramm
	\end{itemize}
\end{itemize}
\subsubsection{Out-of-Order Execution}
\begin{itemize}
	\item Abarbeitung der Microops abweichend von der Programmreihenfolge
	\begin{itemize}
		\item Scheduler (Reservation Station)
		\begin{itemize}
			\item Sendet Microops an die Rechenwerke sobald Operanden verfügbar sind
			\item Microops einer Instruktion müssen nicht zusammen abgearbeitet werden
		\end{itemize}
		\item Reorder Buffer (ROB)
		\begin{itemize}
			\item Zusätzliche Register zur Speicherung der Ergebnisse (Register Renaming)
			\item Zustand der für Software sichtbaren Register wird in Programmreihenfolge aktualisiert (In-order completion)
		\end{itemize}
	\end{itemize}
\end{itemize}
\subsection{Pentium 2 / Pentium 3}
\begin{itemize}
	\item Weiterentwicklung des PPentium Pro
	\begin{itemize}
		\item 3-fach superskalar
		\item 2x 16KB L1-Cache
		\item Zunächst Slot Prozessoren mit L2-Cache in zweitem Chip
		\item später mit on-die L2-Cache wieder in Sockelbauweise
	\end{itemize}
	\item Pentium 3 mit SSE
\end{itemize}
\subsubsection{Streaming SIMD Extensions (SSE)}
\begin{itemize}
	\item Register FILL?
	\item Datentypen FILL?
\end{itemize}
\subsection{Pentium 4}
\begin{itemize}
	\item Designziel hohe Taktfrequenz
	\begin{itemize}
		\item Frequenz begrenzt durch Länge der Pipelinestufen
		\item Extrem lange Pipeline durch wetieres Aufteilen der einzelnen Phasen
		\begin{itemize}
			\item erste Modelle mit 20 Stufen, später 31 (vgl. Pentium 3: 10 Stufen)
		\end{itemize}
		\item 2006 eingestellt, da hohe Frequenzen u hohem Stromverbrauch führten
	\end{itemize}
	\item Execution Trace Cache
	\begin{itemize}
		\item Kein gewöhnlicher L1 Instruction Cache
		\item Speicherung bereits dekodierter Instruktionen
	\end{itemize}
	\item HyperThreading
	\begin{itemize}
		\item Betriebssystem sieht zwei logische Prozessoren pro CPU
		\item Doppelte Registersätze, gemeinsame Nutzung der Rechenwerke
	\end{itemize}
	\item Befehlssatzerweiterungen: SSE2, ab 2004 SSE3
\end{itemize}
\subsubsection{Netburst Mikroarchitektur}
\begin{itemize}
	\item Geringe Decoder Leistung
	\begin{itemize}
		\item bei Misses im Trace Cache nur 1 Microop pro Takt
	\end{itemize}
	\item 64 Bit breite SIMD Einheiten
	\begin{itemize}
		\item SSE Befehle in 2 Operationen
	\end{itemize}
	\item 126 Microops ROB
	\item 2 Integer ALUs
	\item 2 FP Einheiten
	\item L1 Cache pro Kern
	\begin{itemize}
		\item 128 Bit lesen/schreiben pro Takt
	\end{itemize}
	\item Hyperthreading
	\begin{itemize}
		\item 2 Threads gleichzeitig
	\end{itemize}
\end{itemize}
\subsubsection{SSE Erweiterungen}
\begin{itemize}
	\item SSE 2
	\begin{itemize}
		\item 64-Bit Floating Point Befehle (double precision)
		\item 2 Operationen pro Befehl
	\end{itemize}
	\item SSE 3
	\begin{itemize}
		\item Mehrere Operanden aus einem Register
		\item Reduziert Kopieroperationen
	\end{itemize}
\end{itemize}
\subsection{Pentium M/ Core Solo/ Core Duo}
\begin{itemize}
	\item Parallelentwicklung zu Pentium 4
	\item Basieren auf Pentium 3
	\item Energiesparende Architektur für Mobilrechner
	\begin{itemize}
		\item Speedstep Technologie
		\begin{itemize}
			\item Anpassung der Taktfrequenz an Auslastung
			\item Reduziert Leistungsaufnahme während Programme ausgeführt werden
		\end{itemize}
		\item Clock Gating
		\begin{itemize}
			\item Trennung von Logikblöcken vom Taktsignal
			\item Reduziert Leistungsaufnahme in Leerlaufphasen
		\end{itemize}
	\end{itemize}
\end{itemize}
\subsection{Intel64 Prozessoren (Auswahl)}
\begin{itemize}
	\item 2004 Pentium 3 /Pentium D
	\item 2006 Core2 Duo, Core2Quad, Xeon54xx
	\item 2008 Core i5/i7, Xeon 55xx (Nehalem)
	\item 2010 Core i3/i5/i7, Xeon 56xx (Westmere)
	\item 2011 2.Gen i3/5/7, Xeon E3 (Sandy Bridge)
	\begin{itemize}
		\item integrierte GPU
		\item Advanced Vector Extansions (AVX)
	\end{itemize}
	\item 2012 3.Gen, Xeon E3 v2 (Ivy Bridge)
	\item 2013 4.Gen, Xeon E3 v3 (Haswell)
\end{itemize}
\subsubsection{Befehlssatz}
\begin{itemize}
	\item IA-32 Befehlssatz auf 64 Bit Verarbetungsbreite erweitert
	\item Registeranzahl verdoppelt
	\begin{itemize}
		\item Weniger Stackzugriffe nötig
		\item Erhöhte Codegröße
	\end{itemize}
	\item Größerer virtueller Adressraum
\end{itemize}
\subsection{Multicore Prozessoren}
\begin{itemize}
	\item Moores Law
	\item Leistung einzelner Prozessoren nicht beliebig steigerbar
	\begin{itemize}
		\item Höhere Grade an Superskalarität erhöhen Rechenleistung nicht proportional aufgrund von Abhängigkeiten zwischen Befehlen
		\item Leistungssteigerungen durch Pipelining begrenzt durch Verzweigungen im Code
	\end{itemize}
	\item Multi-Core Prozessoren
	\begin{itemize}
		\item Leistungssteigerung durch Duplikation von Teilen des Prozessors
		\item Erfordert Anpassung der Software an Nutzung mehrerer Kerne
	\end{itemize}
\end{itemize}
\subsubsection{Entwicklung des Energieverbrauchs}
\begin{itemize}
	\item Kühlung limitert Verbrauch pro Prozessor
	\item Mehr Kerne mit weniger Frequenz sind effizienter für parallele Anwendungen
\end{itemize}
\subsection{Intel Core Microarchitektur Core2Duo}
\begin{itemize}
	\item Decodiert bis zu 4 Instruktionen pro Takt (5 mit Makroop-Fusion)
	\item 128 Bit breite SIMD Einheiten 
	\item 96 Microops ROB
	\item Verarbeitung von bis zu 6 Microops gleichzeitig
	\item L1-Cache pro Kern
	\item L2-Cache und FSB von beiden Kernen genutzt
\end{itemize}
\subsection{Intel Nehalem Mikroarchitektur}
\begin{itemize}
	\item Prozessorkerne kaum verändert gegenüber Core Mikroarchtektur
	\begin{itemize}
		\item SSE 4.2
		\item Hyperthreading
	\end{itemize}
	\item L2-Cache pro Kern
	\item Gemeinsamer L4-Cache für alle Cores
	\item Integrierter Speichercontroller
	\item FSB ersetzt durch Intel QuickPath Interconnect
\end{itemize}