%!TEX root = ../head.tex

\chapter{Übung}
\section{Einführung}
\subsection{von-Neumann}
\subsubsection{Komponenten des v. Neumann Architektur}
	\begin{itemize}
		\item CPU
		\begin{itemize}
			\item Steuerwerk
			\begin{itemize}
				\item steuert die Befehlsabarbeitung
				\item Befehlszähler (program counter)\(\to\) Instruction Fetch (Befehl holen) \\ \(\to\) Adresse des Befehls steht im pc		
				\item Befehlsregister \(\to\) Befehlswort ins Befehlsregister laden
				\item Befehlsdekoder \(\to\) ID (Instruktction Decode)
				\item zentrale Steuerschleife \(\to\) EX (execute - Befehl ausführen)
				\begin{itemize}
					\item CISC, Abarbeitung des Befehls unter Aufsicht der zentralen Steuerschleife
					\item RISC \(\to\) nutzt das Rechenwerk, ALU
				\end{itemize}
				\item Steuer -und Statusregister (Flag Overflow) \(\to\) WB (Write Back)
			\end{itemize}
			\item Rechenwerk
		\end{itemize}
		\item Speicher
		\begin{itemize}
			\item Programmkode und Daten liegen im gleichen Speicher
		\end{itemize}
		\item Bus
		\begin{itemize}
			\item v.Neumannscher-Flaschenhals: Daten + Befehle müssen über den BUS
			\begin{itemize}
				\item IF \(\to\) Bus
				\item ID
				\item EX \(\to\) Bus (wenn Operanden geholt werden
				\item WB \(\to\) Bus
			\end{itemize}
		\end{itemize}
	\end{itemize}
\subsection{v.Neumann vs. Harvard}
\subsubsection{Harvard}
\begin{itemize}
	\item Trennung von Befehls und Datenspeicher: Befehlsspeicher \(\to\) VN \(\to\) CPU \(\to\) Verbindungseinrichtung (z.B. Bus (VN)) \(\to\) Datenspeicher
	\item heutige Anwendung: Getrennter L1-Cache in L1I- und L1D-Cache
\end{itemize}
\subsection{Def. von Brooks vs Giloi}
\subsubsection{Brooks (1962)}
Rechnerarchitektur, wie andere Architekturen, ist die Kunst der Bestimmung von Nutzerbedürfnissen nach einer Struktur, die so zu entwerfen ist, dass sie jene Bedürfnisse so effektiv wie möglich hinsichtlich ökonomischer und technologischer Erfordernisse erfüllt.
\begin{itemize}
	\item gilt auch für jede Bauarchitektur
	\item bis Ende der 70er Jahre bezog sich Rechnerarchitektur vor allem auf die Programmierschnittstelle 
	\begin{itemize}
		\item Maschinenbefehlssatz (meist Assemblerbefehle) 
		\item Interruptbehandlung (maskierbare + nichtmaskierbare Interrupts)
		\item Registersatz
		\item Adressierungsarten (Basisadressierung, indirekte Adressierung, direkte Adressierung)
		\item Ein-/Ausgabe
	\end{itemize}
\end{itemize}
\subsubsection{Giloi}
z.B. Maschinendarstellung eines Floating Point Wertes Single Precision
\begin{itemize}
	\item Single Precision \(\to\) 32 Bit
	\item IFEE 754: |Sign|Charakteristik (Exponent + Bias|Mantisse| \(\to\) Mantisse wird so weit verschoben, bis führende 1 herausfällt
\end{itemize}
\subsection{RA-Definition Begriffe}
\textbf{Rechnerarchitektur}
	\begin{itemize}
		\item Hardware-Struktur
		\begin{itemize}
			\item Hardwarebetriebsmittelstruktur
			\begin{itemize}
				\item Prozessorstruktur
				\begin{itemize}
					\item 1985 Intel 80 386 (erster 32-Bit Prozessor) \(\to\) nur Integer Unit
					\item 1987 Intel 80 387 (erster Floating Point Unit, FPU)
					\item 1993 Pentium 1: V-Pipe(IU) und U-Pipe (IU oder Teil der FPU) \(\to\) 2 Betriebsarten: IU+IU, IU+FPU
					\item 1995 Pentium Pro: P6-Architektur \(\to\) heutige Core-Architektur ist davon abgeleitet
				\end{itemize}
				\item Speicherstruktur
				\begin{itemize}
					\item intern: Register (L1,L2,L3- Cache, DRAM, Festplatte, Archiv, ...)
					\item zwischen Prozessoren: gemeinsamer Speicher \(\Rightarrow\) CPU 1 \(\to\) CPU N haben gemeinsamen MEMORY || \\ verteilter Speicher \(\Rightarrow\) CPU 1, RAM 1 \(\to\) CPU N, RAM N; verbunden durch Verbindungsnetzwerk
				\end{itemize}
			\end{itemize}
			\item Verbindungsstruktur
			\begin{itemize}
				\item intern
				\begin{itemize}
					\item Adressbus
					\item Steuerbus
					\item Datenbus
				\end{itemize}
				\item extern 
				\begin{itemize}
					\item Verbindungsnetzwerk unterschiedlicher Typologie (Hypercube, 2D Gitter, ...)
				\end{itemize}
			\end{itemize}
			\item Kooperationsregeln (z.B. Master-Slave)
		\end{itemize}
		\item Operationspprinzip
		\begin{itemize}
			\item Informationsstruktur
			\begin{itemize}
				\item Klassen von Datentypen (Byte, Wort, ...)
				\item Menge der Maschinendarstellungen der Datenobjekte
			\end{itemize}
			\item Steuerungsstruktur
			\begin{itemize}
				\item Ablaufsteuerung, pc-getrieben \(\to\) unsere üblichen Rechner 
				\item Ablaufsteuerung, datengetrieben (Datenflussrechner) \(\to\) wenn die Daten da sind wird automatisch die Operation ausgeführt
				\item Datenzugriffssteuerung  \(\to\) Zugriff über Adresslogik, einfache Wertzuordnung, Assoziativer Zugriff (Adresse und Inhalt werden gemeinsam gespeichert) \(\to\) Caches
			\end{itemize}
		\end{itemize}
	\end{itemize}
\subsubsection{Begriffsklärung}
\begin{itemize}
	\item [RA]/[HW-Struktur]/[HW-Betriebsmittel-Struktur]/[Prozessorstruktur]/[\textbf{Steuerwerk}]
	\item [RA]/[HW-Struktur]/[HW-Betriebsmittel-Struktur]/[Speicherstruktur]/[\textbf{Register}]
	\item [RA]/[HW-Struktur]/[Verbindungsstruktur]/[\textbf{Speicherbus}]
	\item [RA]/[Operationsprinzip]/[Informationsstruktur]/[Menge der Maschinendarstellungen der Datenobjekte]/[\textbf{Festkommadatenformat} nach IEEE 754]
	\item[RA]/[Operationsprinzip]/[Informationsstruktur]/[Klassen von Datentypen]/\\ Strukturdatentypen]/ [\textbf{Doppelt verkettete Liste}]
	\item [RA]/[Hardware-Struktur]/[HW-Betriebsmittelstruktur]/[Speicherstruktur]/[\textbf{Cache}]
	\item [RA]/[Operationsprinzip]/[Informationsstruktur]/[Menge der Maschinendarstellungen der Datenobjekte]/[\textbf{Gleitkomma-Datenformate} nach IEEE 754]
	\item [RA]/[Operationsprinzip]/[Steuerungsstruktur]/Ablaufsteuerung]/\\\textbf{Program-Counter getriebene Ablaufsteuerung}]
	\item [RA]/[Operationsprinzip]/[Informationsstruktur]/[Menge der Funktionen, die auf die Datenobjekte anwendbar sind]/[\textbf{Assemblerbefehl: ADD R6, R4, R1}]
	\item [RA]/[HW-Struktur]/[\textbf{Verbindungsnetzwerk zwischen den Prozessoren}]
	\item [RA]/[Operationsprinzip]/[Steuerungsstruktur]/Dateizugriffsteuerung]/[\textbf{Zugriff auf den Cache}]
\end{itemize}
\section{Einführung}
\subsection{Moores Law}
Die Anzahl der Transistoren pro Chip verdoppelt sich alle 1,5 bis 2 Jahre (1965).
\subsubsection{Was macht man mit diesen Transistoren?}
\begin{itemize}
	\item Erhöhung der Prozessorleistung \\ \(\to\) Taktfrequenz kann erhöht werden, da bei kleineren Transistoren kleinere Kapazitäten umgeladen werden müssen (CMOS-Technik)
	\begin{itemize}
		\item 1985 Intel 80382 (erster 32-Bit Prozessor) \\ \(\to\) hatte nur eine Integer-Unit und keinen Cache
	\end{itemize}
	\item Verarbeitungsbreite erhöht (4-bit, 8-bit, 16-bit, 32-bit, 64-bit)
	\item Erhöhung der Anzahl der Verarbeitungseinheiten
	\begin{itemize}
		\item 1989: 80486
		\begin{itemize}
			\item eine FPU (Floating Point Unit)
			\item eine IU (Integer Unit)
		\end{itemize}
		\item Intel Itanium
		\begin{itemize}
			\item 2 FPU's
			\item 6 IU's
		\end{itemize}
	\end{itemize}
\end{itemize}
\subsubsection{Weshalb wir die Anzahl der Verarbeitungseinheiten nicht weiter erhöht?}
ILP (Instruction Level Parallelism)\\
Problem: Zu viele Funktionseinheiten führen zu keinem zusätzlichen Geschwindigkeitsgewinn (Sp. Speedup), da viele Befehle Datenabhängigkeiten aufweisen und so zu wenig unabhängige Befehle vorhanden sind.
\subsubsection{Multicore-Prozessoren}
\begin{itemize}
	\item [2001] IBM: erster DualCore Prozessor
	\item [2005] Intel, AMD 	
\end{itemize}
Problem: Wenn man Leistung umsetzen will muss man sich mit paralleler Programmierung beschäftigen.
\subsubsection{Lücke zwischen Prozessorleistung und Zugriffszeit auf den DRAM verkleinern}
\(\to\) Caches: benötigen ca. \(\frac{1}{3}\) der Chipfläche
\begin{itemize}
	\item L1-Cache: Harvard-Architektur
	\begin{itemize}
		\item L1-Instruction-Cache
		\item L1-Data-Cache
	\end{itemize}
	\item L2-Cache: meistens nicht getrennt (es gibt Ausnahmen: Intel Itanium Motecito)
	\item L3-Cache gemeinsam
\end{itemize}
\subsubsection{Integration weiterer Baugruppen}
z.B.: GPU (Graphic Processing Unit)
\subsection{Klassifikationen nach Flynn}
\begin{enumerate}
	\item Flynnsche Kategorien
	\begin{enumerate}
		\item SISD Single Instruction Stream Single Data Stream
		\begin{itemize}
			\item klassischer von Neumann Rechner
			\item Single Core Processor unter bestimmten Voraussetzungen:
			\begin{itemize}
				\item Eingang: sequentielle Folge von Befehlen
				\item Ausgang: Sequentielle Folge von Ergebnissen
			\end{itemize}
		\end{itemize}
		\item SIMD Single Instruction Stream Multiple Data Streams
		\begin{itemize}
			\item Vektoraddition kann man durchführen mit
			\begin{itemize}
				\item Vektorrechner
				\item Feldrechner: ein Universalprozessor steuert die gesamte Abarbeitung, sehr viele einfache Verarbeitungseinheiten (processing elements, PE) führen zu einem Zeitpunkt die gleiche Operation aus.
				\item Unterschiede:
			\end{itemize}
		\end{itemize}
		\item MISD Multiple Instruction Streams Single Data Stream\\\(\to\) leere Klasse
		\item MIMD Multiple Instruction Streams Multiple Data Streams
		\begin{itemize}
			\item Multiprozessorsystem (MPS)
			\item Cluster von Workstations 
			\item Nachteil: viel zu grob für alle MPS und COW \\ \(\to\)  in der Literatur gibt es Erweiterungen zur Flynnschen Klasse MMID:
		\end{itemize}
	\end{enumerate}
		
	\medskip
						
	\Tree [.MIMD [.{Speichergekoppelte MPS} [.NUMA NL-NUMA CL-NUMA ] UMA COMA ] [.{Nachrichtengekoppelte MPS} COW MPP ] ].MIMD
	
	\item Flynssches Klassifikationsschema
\end{enumerate}
\subsection{MMX, SSE, AVX}
\begin{itemize}
	\item MMX Mulit Media Extensions
	\begin{itemize}
		\item 1996 Pentium
		\item 64-Bit Register
		\item für Integer Verarbeitung
		\item Flynn SIMD
	\end{itemize}
	\item SSE Steuerung SIMD Extensions
	\begin{itemize}
		\item 1999 Pentium 3
		\item SSE 2 2001 Pentium 4
		\item MIMX mit eingebunden
		\item Flynn SIMD
	\end{itemize}
	\item Advanced Vector Extensions
	\begin{itemize}
		\item 2011 Sandy-Bridge
		\item 256Bit Register (für Floating-Point-Ops)
		\item 8*64Bit
		\item 16*32Bit
	\end{itemize}
	\item AVX 2
	\begin{itemize}
		\item 256Bit auch für Integer-Befehle
		\item Unterstützung FMA (Fused Multiply Add)
	\end{itemize}
	\item AVX 512
	\begin{itemize}
		\item Ende 2015 
		\item 512Bit Register
	\end{itemize}
\end{itemize}

\section{Prozessoren / Pipelifting}
\subsection{Adressierungsarten}
\begin{enumerate}
	\item Immediate Operand
	\begin{itemize}
		\item Operand stehlt als Konstante im Befehl: \\
		z.B. MOVE B R3, hash32\\
		oder Add R1, hash17 \(\to\) Addiert den Wert 17 zu Inhalt von R1
	\end{itemize}
	\item Immediate Adresse
	\begin{itemize}
		\item Speicheradressierung direkt: \\
		Effektiver: Adresse steht als absolute Adresse im Befehl \\
		Operand steht im Speicher:\\
		z.B.: Add 0xFFC0: hash323 
	\end{itemize}
	\item Register Direkt
	\begin{itemize}
		\item Adresse steht als kurze Registeradresse im Befehl 
		z.B.: 3Bit für IA 32, Operand steht im Register: \\
		z.B.: MOVE W SP, R0 transportiert den Wortinhalt von R0 in das Stack-Pointer-Register SP
	\end{itemize}
	\item Register Indirekt
	\begin{itemize}
		\item Effektive Adresse steht im Register
		\item Adressierung erfolgt indirekt über Registerinhalt
		\item Adressierung wird durch runde Klammern mit der Bedeutung "Inhalt von Register"
		\item z.B.: MOVE H R1,(R0)  transportiert einen 16Bit Speicheroperanden; diesen Adressen in R0 steht nach R1
	\end{itemize}
	\item Register Indirekt mit Displacement
	\begin{itemize}
		\item Die im Register stehende Adresse wirkt als Basisadresse und wird nicht verändert (steht in Klammer) 
		\item z.B.: MOVE H R2, hash4 (R3)
		\item transportiert einen 16Bit Speicheroperanden nach R2
		\item Basisadresse steht in R3
		\item Adresse des Speicheroperanden = Basisadr. + Displacement (hash4)
	\end{itemize}
\end{enumerate}
\subsection{scale-potenz}
scaled indexed addressing mode \\
img siehe Übungsblatt
\begin{itemize}
	\item Basisadresse + Displacement + Index*Scale = Adresse des Operanden
	\item z.B. Im R1 steht 1000 im R2 steht Index 4:\\
	MOVE R0, hash8(R1)(R2 * hash4) \(\to\) mit R0 von Adresse 1024\\
	MOVE R0, hash1000(R1)(R2 * hash2) \(\to\) mit R0 von adresse 4000\\
	MOVE R0, hash1000(R2*hash8) \(\to\) mit R0 von Adresse 1032
	\item Weshalb nur eine 2er Potenz für scale?\\
	\(\to\) * kein universeller Multiplizierer: mach nur Verschiebung
\end{itemize}
\subsection{Speedup}
z.B. Intel 80486 Pipeline
\begin{itemize}
	\item Fetch Instruction FI
	\item Main instruction Decode D1
	\begin{itemize}
		\item Befehlslänge einstellen?
		\item Operanden decodieren
	\end{itemize}
	\item Secondary instruction Decode D2
	\item execution EX
	\item Write Back WB
\end{itemize}
\begin{tabularx}{\textwidth}{|X|X|X|X|X|X|X|X|X|X|}
\hline
	&1&2&3&4&5&6&7&8&9\\
\hline
1 & IF & D1 & D2 & EX & WB &&&&\\
\hline
2 && IF & D1 & D2 & EX & WB &&& \\
\hline
3 &&& IF & D1 & D2 & EX & WB && \\
\hline
4 &&&& IF & D1 & D2 & EX & WB &\\
\hline
5 &&&&& IF & D1 & D2 & EX & WB \\
\hline
\end{tabularx}

\bigskip

k-1 Zeitschritte Einlaufphase \\
ab k pro Takt 1 Ergebnis (n-Mal)\\
\begin{align*}
	T_{Pipe} &= k-1 +n \\
	&= 4 + 30 \\
	&= 34 \\
	S_{P_{Pipe}} &= \frac{T_1}{T_{P_{Pipe}}}\\
	&= \frac{150}{34} \\
	&= 4,41 \\
\end{align*}
\subsection{}
\begin{enumerate}
	\item
	\begin{itemize}
		\item IPS : Instruction per Second
		\begin{itemize}
			\item gibt an wie viele Maschinenbefehle pro Sekunde ausgeführt werden können (Integer, Floating Point, load/store, Sprung-Befehle, ...)
			\item Vorteile: einfache Bestimmung da keine Trennung der Befehle notwendig
			\item Nachteile: nicht für alles zu gebrauchen z.B. Rechnen arbeitet vorweigend mit Floating Point Operationen double Precision, Einflüsse durch RISC \(\leftrightarrow\) CISC: mehr Instruktionen als CISC bei gleichem Programm; Compilerabhängiger Programmablauf, ..., Art der Operationen: 64-Bit \(\leftrightarrow\) 16-Bit
		\end{itemize}
		\item IOPS : Integer Operation Per Second
		\begin{itemize}
			\item Vorteile: hohe Relevanz für Anwendungen die vorwiegend mit Integer Operationen arbeiten z.B. Bitverarbeitung
			\item Nachteile: für Rechnen nicht so interessant, da meistens FP - Operationen
			\item Einflüsse: Compiler, Genauigketi und Art der Operation (32Bit Int Div \(\leftrightarrow\) 16Bit Integer Div), CISC - RISC
		\end{itemize}
		\item FLOPS Floating Point Operations per Second
		\begin{itemize}
			\item ist wichtige Kenngröße für das wissenschaftliche Rechnen
			\item Top 500- Liste
			\begin{itemize}
				\item Auflistung der 500 leistungsfähigsten Computer der Welt
				\item Basis der Einordnung ist
				\begin{itemize}
					\item UNPACK-Benchmark läuft auf jeder Maschine
					\item erreichte PFLOPS ist Basis für Einordnung
				\end{itemize}
			\end{itemize}
			\item Probleme:
			\begin{itemize}
				\item hängt stark von der Anwendung ab
				\item unterschiedliche Komplexität der Operation wird nicht berücksichtigt (ADD, DIV)
				\item für Integer Probleme wie z.B. Bildverarbeitung nicht aussagekräftig
			\end{itemize}
		\end{itemize}
		\item IOOPS Input/Output Operations per Second
		\begin{itemize}
			\item werden von Vertreibern von Festplatten, Solid State Disks und SAN (Storage Arial Networks) angegeben
			\begin{itemize}
				\item z.B.: Intel Solid State Drive 910
				\begin{itemize}
					\item 800GB
					\item IOOPS (Random 4k)- Herstellerangabe
					\item Read: 180.000
					\item Write 75.000
				\end{itemize}
				\item z.B.: Western Digital Velori Raptor
				\begin{itemize}
					\item 600GB
					\item IOOPS (Random 4k)- Messung
					\item Read: 140
					\item Write 120
				\end{itemize}
			\end{itemize}
			\item Benchmarks: IOmeter (Itel), IOzone
			\item Unterscheidung:
			\begin{enumerate}
				\item Random: Positionen zufällig gewählt (kein Streaming)
				\item Sequentiell: z.B. Read lesen von aufeinanderfolgenden Speicherplätzen (Streaming)
			\end{enumerate}
			\item Hinweis: IOOPS werden fälschlicherweise oft als IOPS in der Literatur bezeichnet
		\end{itemize}
	\end{itemize}
	\item Für die Bewertung von Allzwecksystemen sollten alle 4 Kenngrößen für eine Reihe von Programmen getestet werden, damit die verschiedenen Nutzen sich einordnen können\\
	\(\to\) mit Theoretischen Peak Performance Werten vergleichen
	\begin{itemize}
		\item Peak Performance Werte
		\begin{itemize}
			\item sind Bestwerte, die anhand der Architektur berechnet werden
			\item praktisch werden diese Obergrenzen nicht erreicht
			\item z.B.: Top 500 Liste
			\begin{itemize}
				\item neben Linpack FLOPS wird auch die Theoretische Floating Point Peak Performance angegeben
			\end{itemize}
		\end{itemize}
	\end{itemize}
\end{enumerate}
\section{}
\subsection{SPARC INTEL AMD}
\begin{enumerate}
	\item SPARC64 III 
	\begin{enumerate}
		\item Berechnung der Theoretischen Peak Performance IPS IOPS FLOPS
		\begin{align*}
			\text{geg.: } &f = 330  \text{ MHz Taktfrequenz} \\
			&2 \text{ Integer Units}\\
			&2 \text{ Floating Point Units}\\
			&4 \text{ Befehle pro Takt}\\
			&\text{IPS}\\
			\text{IPS} &= f \cdot \text{ IPC} &&\text{IPC = Instructions per Cycle(Clock)}\\
			&= 330 \cdot 10^6 \cdot 4 = 1,32 \text{ GiPS}\\
			\text{IOPS} &= f \cdot \text{IO-PC}\\
			&= 330 \cdot 10^6 \cdot 2 = 660 \text{ MIOPS}\\
			\text{FLOPS} &= f \cdot \text{FLO-PC}\\
			&= 330 \cdot 10^6 \cdot 2 = 660 \text{MFLOPS}
		\end{align*}
		\item Wie viele IOOPS?
		\begin{itemize}
			\item Volle Verarbetungsleistung wird erreicht, wenn 2 IOP und 2 FLOP pro Takt ausgeführt werden
			\item Im worst case (bezogen auf den Speicherzugriff) müssen gleichzeitig Operanden und Befehle aus dem Speicher geholt werden und Ergebnisse zurückgeschrieben werden
			\begin{itemize}
				\item 4 IOOP für Instruction Fetch
				\item 8 IOOP für Operand Fetch
				\item 4 IOOP für Write Back
				\item \(\to\) Gesamt: 16 IOOP pro Takt
			\end{itemize}
			Total IOOP \(= f \cdot \text{ IOOP-PC} = 330 \cdot 10^6 \cdot 16 = 5,28\) GIOOPS \\
			Aktuell nicht Realisierbar in oberen Speicherhierarchieebenen, daher meist Optimierung der Speicherzugriffe durch das Laden mehrerer Instruktionen/Operanden mit eine I/O -Zugriff
		\end{itemize}
		\item Fused Multiply Add\\
		im eingelaufenen Zustand der Pipeline wird pro Takt eine Multiplikation und eine Addition fertig
		\begin{itemize}
			\item hat das Einfluss auf IPS?\\
			kein Einfluss
			\begin{itemize}
				\item mit FMA 
				\begin{itemize}
					\item Multiply/Add ist jetzt eine Instruktion \(X = A \cdot B + C\)
					\item diese Instruction dauert einen Takt
				\end{itemize}
				\item ohne FMA
				\begin{itemize}
					\item Multiply/add sind 2 Instruktionen
					\item \(\to\) dauert 2 Takte
				\end{itemize}
			\end{itemize}
			\item hat das Einfluss auf FLOPS?
			\begin{itemize}
				\item FLOPS verdoppeln sich
			\end{itemize}
			\item hat das Einfluss auf IOPS?
			\begin{itemize}
				\item bis AVX2 ab Haswell gab es kein FMA für Integer Operationen
				\item ab AVX2 auch FMA für Integer \(\to\) Verdopplung von IOPS
			\end{itemize}
		\end{itemize}
	\end{enumerate}
	\item INTEL CORE i7-2600K Sandy Bridge
	\begin{enumerate}
		\item Floating Point Peak Performance (Double Precision)
		\begin{itemize}
			\item 4 Kerne
			\item 3,4GHz
			\item pro Kern 5 Instruktionen laden + decodieren
			\item pro Kern 2 FPUs
			\item AVX (256Bit)
		\end{itemize}
		FPPP = Taktfrequenz * Anzahl der gleichzeitigen FP Operationen * Anzahl der Kerne\\
		= \(3,4 \cdot 10^9 \cdot 4\text{ (AVX = 64Bit = Double Precision) } \cdot 2 \text{ FPUs} = 108,8 \text{ GFLOPS} \)
		\item Bandbreite = FPPP * Operanden * Operandenbandbreite
		\begin{align*}
			= 108,8 \cdot 10^9 \text{ FLOPS } \cdot s^{-1} \cdot 3 \text{ Operanden } \cdot 8 \frac{\text{ Byte }}{\text{ Operand }}\text{ IEEE STANDARD}\\
			&= 2,6 \text{ TB/s} \to \text{ geht nur mit intensiver Cache Nutzung}
		\end{align*}
	\end{enumerate}
	\item AMD FX 8350
	\begin{enumerate}
		\item theoretische FPPP
		\begin{align*}
		\text{geg.: } &4 \text{ GHz Taktfrequenz}\\
		& 8 \text{ Integer Kerne}\\
		& 2 \text{ Integer Kerne teilen sich eine FPU }\\
		& \text{Fused Multiply Add}\\
		& 2 \text{ Pipelines pro FPU, jede Pipeline 128 Bit }\\
		\text{FPPP } &=  \text{ Taktfrequenz } \cdot \text{  Anzahl gleichzeitiger FP Operationen }\\
		&= 4 \cdot 10^9 s^{-1} \cdot 2 \text{ (Anzahl der Pipelines) } \cdot 2 ( 128\text{Bit}) \cdot 2 \text{ (FMA)} \\
		&= 32 \text{ GFLOPS}
		\end{align*}
		\item FPPP für ganzen Prozessor
		\begin{align*}
		\text{FPPP } &= \text{ FPPP einer FPU } \cdot \text{ Anzahl der FPUs }\\
		&= 32 \cdot 4 = 128 \text{ GFLOPS}
		\end{align*}
	\end{enumerate}
\end{enumerate}