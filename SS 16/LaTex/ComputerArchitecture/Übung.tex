%!TEX root = ../head.tex

\chapter{Übung}
\section{Einführung}
\subsection{von-Neumann}
\subsubsection{Komponenten des v. Neumann Architektur}
	\begin{itemize}
		\item CPU
		\begin{itemize}
			\item Steuerwerk
			\begin{itemize}
				\item steuert die Befehlsabarbeitung
				\item Befehlszähler (program counter)\(\to\) Instruction Fetch (Befehl holen) \\ \(\to\) Adresse des Befehls steht im pc		
				\item Befehlsregister \(\to\) Befehlswort ins Befehlsregister laden
				\item Befehlsdekoder \(\to\) ID (Instruktction Decode)
				\item zentrale Steuerschleife \(\to\) EX (execute - Befehl ausführen)
				\begin{itemize}
					\item CISC, Abarbeitung des Befehls unter Aufsicht der zentralen Steuerschleife
					\item RISC \(\to\) nutzt das Rechenwerk, ALU
				\end{itemize}
				\item Steuer -und Statusregister (Flag Overflow) \(\to\) WB (Write Back)
			\end{itemize}
			\item Rechenwerk
		\end{itemize}
		\item Speicher
		\begin{itemize}
			\item Programmkode und Daten liegen im gleichen Speicher
		\end{itemize}
		\item Bus
		\begin{itemize}
			\item v.Neumannscher-Flaschenhals: Daten + Befehle müssen über den BUS
			\begin{itemize}
				\item IF \(\to\) Bus
				\item ID
				\item EX \(\to\) Bus (wenn Operanden geholt werden
				\item WB \(\to\) Bus
			\end{itemize}
		\end{itemize}
	\end{itemize}
\subsection{v.Neumann vs. Harvard}
\subsubsection{Harvard}
\begin{itemize}
	\item Trennung von Befehls und Datenspeicher: Befehlsspeicher \(\to\) VN \(\to\) CPU \(\to\) Verbindungseinrichtung (z.B. Bus (VN)) \(\to\) Datenspeicher
	\item heutige Anwendung: Getrennter L1-Cache in L1I- und L1D-Cache
\end{itemize}
\subsection{Def. von Brooks vs Giloi}
\subsubsection{Brooks (1962)}
Rechnerarchitektur, wie andere Architekturen, ist die Kunst der Bestimmung von Nutzerbedürfnissen nach einer Struktur, die so zu entwerfen ist, dass sie jene Bedürfnisse so effektiv wie möglich hinsichtlich ökonomischer und technologischer Erfordernisse erfüllt.
\begin{itemize}
	\item gilt auch für jede Bauarchitektur
	\item bis Ende der 70er Jahre bezog sich Rechnerarchitektur vor allem auf die Programmierschnittstelle 
	\begin{itemize}
		\item Maschinenbefehlssatz (meist Assemblerbefehle) 
		\item Interruptbehandlung (maskierbare + nichtmaskierbare Interrupts)
		\item Registersatz
		\item Adressierungsarten (Basisadressierung, indirekte Adressierung, direkte Adressierung)
		\item Ein-/Ausgabe
	\end{itemize}
\end{itemize}
\subsubsection{Giloi}
z.B. Maschinendarstellung eines Floating Point Wertes Single Precision
\begin{itemize}
	\item Single Precision \(\to\) 32 Bit
	\item IFEE 754: |Sign|Charakteristik (Exponent + Bias|Mantisse| \(\to\) Mantisse wird so weit verschoben, bis führende 1 herausfällt
\end{itemize}
\subsection{RA-Definition Begriffe}
\textbf{Rechnerarchitektur}
	\begin{itemize}
		\item Hardware-Struktur
		\begin{itemize}
			\item Hardwarebetriebsmittelstruktur
			\begin{itemize}
				\item Prozessorstruktur
				\begin{itemize}
					\item 1985 Intel 80 386 (erster 32-Bit Prozessor) \(\to\) nur Integer Unit
					\item 1987 Intel 80 387 (erster Floating Point Unit, FPU)
					\item 1993 Pentium 1: V-Pipe(IU) und U-Pipe (IU oder Teil der FPU) \(\to\) 2 Betriebsarten: IU+IU, IU+FPU
					\item 1995 Pentium Pro: P6-Architektur \(\to\) heutige Core-Architektur ist davon abgeleitet
				\end{itemize}
				\item Speicherstruktur
				\begin{itemize}
					\item intern: Register (L1,L2,L3- Cache, DRAM, Festplatte, Archiv, ...)
					\item zwischen Prozessoren: gemeinsamer Speicher \(\Rightarrow\) CPU 1 \(\to\) CPU N haben gemeinsamen MEMORY || \\ verteilter Speicher \(\Rightarrow\) CPU 1, RAM 1 \(\to\) CPU N, RAM N; verbunden durch Verbindungsnetzwerk
				\end{itemize}
			\end{itemize}
			\item Verbindungsstruktur
			\begin{itemize}
				\item intern
				\begin{itemize}
					\item Adressbus
					\item Steuerbus
					\item Datenbus
				\end{itemize}
				\item extern 
				\begin{itemize}
					\item Verbindungsnetzwerk unterschiedlicher Typologie (Hypercube, 2D Gitter, ...)
				\end{itemize}
			\end{itemize}
			\item Kooperationsregeln (z.B. Master-Slave)
		\end{itemize}
		\item Operationspprinzip
		\begin{itemize}
			\item Informationsstruktur
			\begin{itemize}
				\item Klassen von Datentypen (Byte, Wort, ...)
				\item Menge der Maschinendarstellungen der Datenobjekte
			\end{itemize}
			\item Steuerungsstruktur
			\begin{itemize}
				\item Ablaufsteuerung, pc-getrieben \(\to\) unsere üblichen Rechner 
				\item Ablaufsteuerung, datengetrieben (Datenflussrechner) \(\to\) wenn die Daten da sind wird automatisch die Operation ausgeführt
				\item Datenzugriffssteuerung  \(\to\) Zugriff über Adresslogik, einfache Wertzuordnung, Assoziativer Zugriff (Adresse und Inhalt werden gemeinsam gespeichert) \(\to\) Caches
			\end{itemize}
		\end{itemize}
	\end{itemize}
\subsubsection{Begriffsklärung}
\begin{itemize}
	\item [RA]/[HW-Struktur]/[HW-Betriebsmittel-Struktur]/[Prozessorstruktur]/[\textbf{Steuerwerk}]
	\item [RA]/[HW-Struktur]/[HW-Betriebsmittel-Struktur]/[Speicherstruktur]/[\textbf{Register}]
	\item [RA]/[HW-Struktur]/[Verbindungsstruktur]/[\textbf{Speicherbus}]
	\item [RA]/[Operationsprinzip]/[Informationsstruktur]/[Menge der Maschinendarstellungen der Datenobjekte]/[\textbf{Festkommadatenformat} nach IEEE 754]
	\item[RA]/[Operationsprinzip]/[Informationsstruktur]/[Klassen von Datentypen]/\\ Strukturdatentypen]/ [\textbf{Doppelt verkettete Liste}]
	\item [RA]/[Hardware-Struktur]/[HW-Betriebsmittelstruktur]/[Speicherstruktur]/[\textbf{Cache}]
	\item [RA]/[Operationsprinzip]/[Informationsstruktur]/[Menge der Maschinendarstellungen der Datenobjekte]/[\textbf{Gleitkomma-Datenformate} nach IEEE 754]
	\item [RA]/[Operationsprinzip]/[Steuerungsstruktur]/Ablaufsteuerung]/\\\textbf{Program-Counter getriebene Ablaufsteuerung}]
	\item [RA]/[Operationsprinzip]/[Informationsstruktur]/[Menge der Funktionen, die auf die Datenobjekte anwendbar sind]/[\textbf{Assemblerbefehl: ADD R6, R4, R1}]
	\item [RA]/[HW-Struktur]/[\textbf{Verbindungsnetzwerk zwischen den Prozessoren}]
	\item [RA]/[Operationsprinzip]/[Steuerungsstruktur]/Dateizugriffsteuerung]/[\textbf{Zugriff auf den Cache}]
\end{itemize}
\section{Einführung}
\subsection{Moores Law}
Die Anzahl der Transistoren pro Chip verdoppelt sich alle 1,5 bis 2 Jahre (1965).
\subsubsection{Was macht man mit diesen Transistoren?}
\begin{itemize}
	\item Erhöhung der Prozessorleistung \\ \(\to\) Taktfrequenz kann erhöht werden, da bei kleineren Transistoren kleinere Kapazitäten umgeladen werden müssen (CMOS-Technik)
	\begin{itemize}
		\item 1985 Intel 80382 (erster 32-Bit Prozessor) \\ \(\to\) hatte nur eine Integer-Unit und keinen Cache
	\end{itemize}
	\item Verarbeitungsbreite erhöht (4-bit, 8-bit, 16-bit, 32-bit, 64-bit)
	\item Erhöhung der Anzahl der Verarbeitungseinheiten
	\begin{itemize}
		\item 1989: 80486
		\begin{itemize}
			\item eine FPU (Floating Point Unit)
			\item eine IU (Integer Unit)
		\end{itemize}
		\item Intel Itanium
		\begin{itemize}
			\item 2 FPU's
			\item 6 IU's
		\end{itemize}
	\end{itemize}
\end{itemize}
\subsubsection{Weshalb wir die Anzahl der Verarbeitungseinheiten nicht weiter erhöht?}
ILP (Instruction Level Parallelism)\\
Problem: Zu viele Funktionseinheiten führen zu keinem zusätzlichen Geschwindigkeitsgewinn (Sp. Speedup), da viele Befehle Datenabhängigkeiten aufweisen und so zu wenig unabhängige Befehle vorhanden sind.
\subsubsection{Multicore-Prozessoren}
\begin{itemize}
	\item [2001] IBM: erster DualCore Prozessor
	\item [2005] Intel, AMD 	
\end{itemize}
Problem: Wenn man Leistung umsetzen will muss man sich mit paralleler Programmierung beschäftigen.
\subsubsection{Lücke zwischen Prozessorleistung und Zugriffszeit auf den DRAM verkleinern}
\(\to\) Caches: benötigen ca. \(\frac{1}{3}\) der Chipfläche
\begin{itemize}
	\item L1-Cache: Harvard-Architektur
	\begin{itemize}
		\item L1-Instruction-Cache
		\item L1-Data-Cache
	\end{itemize}
	\item L2-Cache: meistens nicht getrennt (es gibt Ausnahmen: Intel Itanium Motecito)
	\item L3-Cache gemeinsam
\end{itemize}
\subsubsection{Integration weiterer Baugruppen}
z.B.: GPU (Graphic Processing Unit)
\subsection{Klassifikationen nach Flynn}
\begin{enumerate}
	\item Flynnsche Kategorien
	\begin{enumerate}
		\item SISD Single Instruction Stream Single Data Stream
		\begin{itemize}
			\item klassischer von Neumann Rechner
			\item Single Core Processor unter bestimmten Voraussetzungen:
			\begin{itemize}
				\item Eingang: sequentielle Folge von Befehlen
				\item Ausgang: Sequentielle Folge von Ergebnissen
			\end{itemize}
		\end{itemize}
		\item SIMD Single Instruction Stream Multiple Data Streams
		\begin{itemize}
			\item Vektoraddition kann man durchführen mit
			\begin{itemize}
				\item Vektorrechner
				\item Feldrechner: ein Universalprozessor steuert die gesamte Abarbeitung, sehr viele einfache Verarbeitungseinheiten (processing elements, PE) führen zu einem Zeitpunkt die gleiche Operation aus.
				\item Unterschiede:
			\end{itemize}
		\end{itemize}
		\item MISD Multiple Instruction Streams Single Data Stream\\\(\to\) leere Klasse
		\item MIMD Multiple Instruction Streams Multiple Data Streams
		\begin{itemize}
			\item Multiprozessorsystem (MPS)
			\item Cluster von Workstations 
			\item Nachteil: viel zu grob für alle MPS und COW \\ \(\to\)  in der Literatur gibt es Erweiterungen zur Flynnschen Klasse MMID:
		\end{itemize}
	\end{enumerate}
		
	\medskip
						
	\Tree [.MIMD [.{Speichergekoppelte MPS} [.NUMA NL-NUMA CL-NUMA ] UMA COMA ] [.{Nachrichtengekoppelte MPS} COW MPP ] ].MIMD
	
	\item Flynssches Klassifikationsschema
\end{enumerate}
\subsection{MMX, SSE, AVX}
\begin{itemize}
	\item MMX Mulit Media Extensions
	\begin{itemize}
		\item 1996 Pentium
		\item 64-Bit Register
		\item für Integer Verarbeitung
		\item Flynn SIMD
	\end{itemize}
	\item SSE Steuerung SIMD Extensions
	\begin{itemize}
		\item 1999 Pentium 3
		\item SSE 2 2001 Pentium 4
		\item MIMX mit eingebunden
		\item Flynn SIMD
	\end{itemize}
	\item Advanced Vector Extensions
	\begin{itemize}
		\item 2011 Sandy-Bridge
		\item 256Bit Register (für Floating-Point-Ops)
		\item 8*64Bit
		\item 16*32Bit
	\end{itemize}
	\item AVX 2
	\begin{itemize}
		\item 256Bit auch für Integer-Befehle
		\item Unterstützung FMA (Fused Multiply Add)
	\end{itemize}
	\item AVX 512
	\begin{itemize}
		\item Ende 2015 
		\item 512Bit Register
	\end{itemize}
\end{itemize}

\section{Prozessoren / Pipelifting}
\subsection{Adressierungsarten}
\begin{enumerate}
	\item Immediate Operand
	\begin{itemize}
		\item Operand stehlt als Konstante im Befehl: \\
		z.B. MOVE B R3, hash32\\
		oder Add R1, hash17 \(\to\) Addiert den Wert 17 zu Inhalt von R1
	\end{itemize}
	\item Immediate Adresse
	\begin{itemize}
		\item Speicheradressierung direkt: \\
		Effektiver: Adresse steht als absolute Adresse im Befehl \\
		Operand steht im Speicher:\\
		z.B.: Add 0xFFC0: hash323 
	\end{itemize}
	\item Register Direkt
	\begin{itemize}
		\item Adresse steht als kurze Registeradresse im Befehl 
		z.B.: 3Bit für IA 32, Operand steht im Register: \\
		z.B.: MOVE W SP, R0 transportiert den Wortinhalt von R0 in das Stack-Pointer-Register SP
	\end{itemize}
	\item Register Indirekt
	\begin{itemize}
		\item Effektive Adresse steht im Register
		\item Adressierung erfolgt indirekt über Registerinhalt
		\item Adressierung wird durch runde Klammern mit der Bedeutung "Inhalt von Register"
		\item z.B.: MOVE H R1,(R0)  transportiert einen 16Bit Speicheroperanden; diesen Adressen in R0 steht nach R1
	\end{itemize}
	\item Register Indirekt mit Displacement
	\begin{itemize}
		\item Die im Register stehende Adresse wirkt als Basisadresse und wird nicht verändert (steht in Klammer) 
		\item z.B.: MOVE H R2, hash4 (R3)
		\item transportiert einen 16Bit Speicheroperanden nach R2
		\item Basisadresse steht in R3
		\item Adresse des Speicheroperanden = Basisadr. + Displacement (hash4)
	\end{itemize}
\end{enumerate}
\subsection{scale-potenz}
scaled indexed addressing mode \\
img siehe Übungsblatt
\begin{itemize}
	\item Basisadresse + Displacement + Index*Scale = Adresse des Operanden
	\item z.B. Im R1 steht 1000 im R2 steht Index 4:\\
	MOVE R0, hash8(R1)(R2 * hash4) \(\to\) mit R0 von Adresse 1024\\
	MOVE R0, hash1000(R1)(R2 * hash2) \(\to\) mit R0 von adresse 4000\\
	MOVE R0, hash1000(R2*hash8) \(\to\) mit R0 von Adresse 1032
	\item Weshalb nur eine 2er Potenz für scale?\\
	\(\to\) * kein universeller Multiplizierer: mach nur Verschiebung
\end{itemize}
\subsection{Speedup}
z.B. Intel 80486 Pipeline
\begin{itemize}
	\item Fetch Instruction FI
	\item Main instruction Decode D1
	\begin{itemize}
		\item Befehlslänge einstellen?
		\item Operanden decodieren
	\end{itemize}
	\item Secondary instruction Decode D2
	\item execution EX
	\item Write Back WB
\end{itemize}
\begin{tabularx}{\textwidth}{|X|X|X|X|X|X|X|X|X|X|}
\hline
	&1&2&3&4&5&6&7&8&9\\
\hline
1 & IF & D1 & D2 & EX & WB &&&&\\
\hline
2 && IF & D1 & D2 & EX & WB &&& \\
\hline
3 &&& IF & D1 & D2 & EX & WB && \\
\hline
4 &&&& IF & D1 & D2 & EX & WB &\\
\hline
5 &&&&& IF & D1 & D2 & EX & WB \\
\hline
\end{tabularx}

\bigskip

k-1 Zeitschritte Einlaufphase \\
ab k pro Takt 1 Ergebnis (n-Mal)\\
\begin{align*}
	T_{Pipe} &= k-1 +n \\
	&= 4 + 30 \\
	&= 34 \\
	S_{P_{Pipe}} &= \frac{T_1}{T_{P_{Pipe}}}\\
	&= \frac{150}{34} \\
	&= 4,41 \\
\end{align*}
\subsection{}
\begin{enumerate}
	\item
	\begin{itemize}
		\item IPS : Instruction per Second
		\begin{itemize}
			\item gibt an wie viele Maschinenbefehle pro Sekunde ausgeführt werden können (Integer, Floating Point, load/store, Sprung-Befehle, ...)
			\item Vorteile: einfache Bestimmung da keine Trennung der Befehle notwendig
			\item Nachteile: nicht für alles zu gebrauchen z.B. Rechnen arbeitet vorweigend mit Floating Point Operationen double Precision, Einflüsse durch RISC \(\leftrightarrow\) CISC: mehr Instruktionen als CISC bei gleichem Programm; Compilerabhängiger Programmablauf, ..., Art der Operationen: 64-Bit \(\leftrightarrow\) 16-Bit
		\end{itemize}
		\item IOPS : Integer Operation Per Second
		\begin{itemize}
			\item Vorteile: hohe Relevanz für Anwendungen die vorwiegend mit Integer Operationen arbeiten z.B. Bitverarbeitung
			\item Nachteile: für Rechnen nicht so interessant, da meistens FP - Operationen
			\item Einflüsse: Compiler, Genauigketi und Art der Operation (32Bit Int Div \(\leftrightarrow\) 16Bit Integer Div), CISC - RISC
		\end{itemize}
		\item FLOPS Floating Point Operations per Second
		\begin{itemize}
			\item ist wichtige Kenngröße für das wissenschaftliche Rechnen
			\item Top 500- Liste
			\begin{itemize}
				\item Auflistung der 500 leistungsfähigsten Computer der Welt
				\item Basis der Einordnung ist
				\begin{itemize}
					\item UNPACK-Benchmark läuft auf jeder Maschine
					\item erreichte PFLOPS ist Basis für Einordnung
				\end{itemize}
			\end{itemize}
			\item Probleme:
			\begin{itemize}
				\item hängt stark von der Anwendung ab
				\item unterschiedliche Komplexität der Operation wird nicht berücksichtigt (ADD, DIV)
				\item für Integer Probleme wie z.B. Bildverarbeitung nicht aussagekräftig
			\end{itemize}
		\end{itemize}
		\item IOOPS Input/Output Operations per Second
		\begin{itemize}
			\item werden von Vertreibern von Festplatten, Solid State Disks und SAN (Storage Arial Networks) angegeben
			\begin{itemize}
				\item z.B.: Intel Solid State Drive 910
				\begin{itemize}
					\item 800GB
					\item IOOPS (Random 4k)- Herstellerangabe
					\item Read: 180.000
					\item Write 75.000
				\end{itemize}
				\item z.B.: Western Digital Velori Raptor
				\begin{itemize}
					\item 600GB
					\item IOOPS (Random 4k)- Messung
					\item Read: 140
					\item Write 120
				\end{itemize}
			\end{itemize}
			\item Benchmarks: IOmeter (Itel), IOzone
			\item Unterscheidung:
			\begin{enumerate}
				\item Random: Positionen zufällig gewählt (kein Streaming)
				\item Sequentiell: z.B. Read lesen von aufeinanderfolgenden Speicherplätzen (Streaming)
			\end{enumerate}
			\item Hinweis: IOOPS werden fälschlicherweise oft als IOPS in der Literatur bezeichnet
		\end{itemize}
	\end{itemize}
	\item Für die Bewertung von Allzwecksystemen sollten alle 4 Kenngrößen für eine Reihe von Programmen getestet werden, damit die verschiedenen Nutzen sich einordnen können\\
	\(\to\) mit Theoretischen Peak Performance Werten vergleichen
	\begin{itemize}
		\item Peak Performance Werte
		\begin{itemize}
			\item sind Bestwerte, die anhand der Architektur berechnet werden
			\item praktisch werden diese Obergrenzen nicht erreicht
			\item z.B.: Top 500 Liste
			\begin{itemize}
				\item neben Linpack FLOPS wird auch die Theoretische Floating Point Peak Performance angegeben
			\end{itemize}
		\end{itemize}
	\end{itemize}
\end{enumerate}
\section{}
\subsection{SPARC INTEL AMD}
\begin{enumerate}
	\item SPARC64 III 
	\begin{enumerate}
		\item Berechnung der Theoretischen Peak Performance IPS IOPS FLOPS
		\begin{align*}
			\text{geg.: } &f = 330  \text{ MHz Taktfrequenz} \\
			&2 \text{ Integer Units}\\
			&2 \text{ Floating Point Units}\\
			&4 \text{ Befehle pro Takt}\\
			&\text{IPS}\\
			\text{IPS} &= f \cdot \text{ IPC} &&\text{IPC = Instructions per Cycle(Clock)}\\
			&= 330 \cdot 10^6 \cdot 4 = 1,32 \text{ GiPS}\\
			\text{IOPS} &= f \cdot \text{IO-PC}\\
			&= 330 \cdot 10^6 \cdot 2 = 660 \text{ MIOPS}\\
			\text{FLOPS} &= f \cdot \text{FLO-PC}\\
			&= 330 \cdot 10^6 \cdot 2 = 660 \text{MFLOPS}
		\end{align*}
		\item Wie viele IOOPS?
		\begin{itemize}
			\item Volle Verarbetungsleistung wird erreicht, wenn 2 IOP und 2 FLOP pro Takt ausgeführt werden
			\item Im worst case (bezogen auf den Speicherzugriff) müssen gleichzeitig Operanden und Befehle aus dem Speicher geholt werden und Ergebnisse zurückgeschrieben werden
			\begin{itemize}
				\item 4 IOOP für Instruction Fetch
				\item 8 IOOP für Operand Fetch
				\item 4 IOOP für Write Back
				\item \(\to\) Gesamt: 16 IOOP pro Takt
			\end{itemize}
			Total IOOP \(= f \cdot \text{ IOOP-PC} = 330 \cdot 10^6 \cdot 16 = 5,28\) GIOOPS \\
			Aktuell nicht Realisierbar in oberen Speicherhierarchieebenen, daher meist Optimierung der Speicherzugriffe durch das Laden mehrerer Instruktionen/Operanden mit eine I/O -Zugriff
		\end{itemize}
		\item Fused Multiply Add\\
		im eingelaufenen Zustand der Pipeline wird pro Takt eine Multiplikation und eine Addition fertig
		\begin{itemize}
			\item hat das Einfluss auf IPS?\\
			kein Einfluss
			\begin{itemize}
				\item mit FMA 
				\begin{itemize}
					\item Multiply/Add ist jetzt eine Instruktion \(X = A \cdot B + C\)
					\item diese Instruction dauert einen Takt
				\end{itemize}
				\item ohne FMA
				\begin{itemize}
					\item Multiply/add sind 2 Instruktionen
					\item \(\to\) dauert 2 Takte
				\end{itemize}
			\end{itemize}
			\item hat das Einfluss auf FLOPS?
			\begin{itemize}
				\item FLOPS verdoppeln sich
			\end{itemize}
			\item hat das Einfluss auf IOPS?
			\begin{itemize}
				\item bis AVX2 ab Haswell gab es kein FMA für Integer Operationen
				\item ab AVX2 auch FMA für Integer \(\to\) Verdopplung von IOPS
			\end{itemize}
		\end{itemize}
	\end{enumerate}
	\item INTEL CORE i7-2600K Sandy Bridge
	\begin{enumerate}
		\item Floating Point Peak Performance (Double Precision)
		\begin{itemize}
			\item 4 Kerne
			\item 3,4GHz
			\item pro Kern 5 Instruktionen laden + decodieren
			\item pro Kern 2 FPUs
			\item AVX (256Bit)
		\end{itemize}
		FPPP = Taktfrequenz * Anzahl der gleichzeitigen FP Operationen * Anzahl der Kerne\\
		= \(3,4 \cdot 10^9 \cdot 4\text{ (AVX = 64Bit = Double Precision) } \cdot 2 \text{ FPUs} = 108,8 \text{ GFLOPS} \)
		\item Bandbreite = FPPP * Operanden * Operandenbandbreite
		\begin{align*}
			= 108,8 \cdot 10^9 \text{ FLOPS } \cdot s^{-1} \cdot 3 \text{ Operanden } \cdot 8 \frac{\text{ Byte }}{\text{ Operand }}\text{ IEEE STANDARD}\\
			&= 2,6 \text{ TB/s} \to \text{ geht nur mit intensiver Cache Nutzung}
		\end{align*}
	\end{enumerate}
	\item AMD FX 8350
	\begin{enumerate}
		\item theoretische FPPP
		\begin{align*}
		\text{geg.: } &4 \text{ GHz Taktfrequenz}\\
		& 8 \text{ Integer Kerne}\\
		& 2 \text{ Integer Kerne teilen sich eine FPU }\\
		& \text{Fused Multiply Add}\\
		& 2 \text{ Pipelines pro FPU, jede Pipeline 128 Bit }\\
		\text{FPPP } &=  \text{ Taktfrequenz } \cdot \text{  Anzahl gleichzeitiger FP Operationen }\\
		&= 4 \cdot 10^9 s^{-1} \cdot 2 \text{ (Anzahl der Pipelines) } \cdot 2 ( 128\text{Bit}) \cdot 2 \text{ (FMA)} \\
		&= 32 \text{ GFLOPS}
		\end{align*}
		\item FPPP für ganzen Prozessor
		\begin{align*}
		\text{FPPP } &= \text{ FPPP einer FPU } \cdot \text{ Anzahl der FPUs }\\
		&= 32 \cdot 4 = 128 \text{ GFLOPS}
		\end{align*}
	\end{enumerate}
\end{enumerate}

\section{}
fill 24.05.
\section{HND, RISC, DLX-Architektur, Blatt 3}
\subsection{Hauptkomponenten HDN (3.1)}
Welche Hauptkomponenten nutzt HDN für die Beschreibung von Befehlssätzen?
\begin{itemize}
	\item[$\leftarrow$] Transfer logisch (z.B. GPR[R6], Generel Purpose Register)
	\item[M] Speicherzugriff
	\item[$\leftarrow _n$] Transfer mit expliziter Längenangabe
	\item[\#\#] Verkettungsoperator
	\begin{itemize}
		\item Beispiel: GPR[R4] $\leftarrow _{32} M$[Adresse x] \#\# M[x+2]
	\end{itemize}
	\item[$X^m$] Wiederholungsspezifikation
	\item[$X_{m\ldots n}$] Zugriff auf eine Bitkette
	\begin{itemize}
		\item Beispiel: GPR[R6]$_{0\ldots 23} \leftarrow O^{24}$ 
	\end{itemize}
	\item[$X_n$] Zugriff zum Einzelbit
	\begin{itemize}
		\item Beispiel: GPR[R5]$_0\ldots 23\leftarrow M([\text{Adresse x}])_0^{24}$
	\end{itemize}
\end{itemize}
\subsection{RISC-Architekturen (3.2)}
Nennen Sie wesentliche Merkmale von RISC-Architekturen.
\begin{itemize}
	\item wenige Befehlsformate fester Länge (für DIX-Architekturen 32 Bit)
	\begin{itemize}
		\item erleichtert Pipelining erheblich. Durch konstante Befehlslänge kann schon der nächste Befehl geholt werden. (IF Instruction Fetch) während der vorhergehende Befehl dekodiert wird.
	\end{itemize}
	\item Ein-Zyklus Operationen
	\begin{itemize}
		\item im eingelaufenen Zustand der Pipeline stellt jede Verarbeitungseinheit pro Takt einen Befehl fertig
	\end{itemize}
	\item Load/Store-GPR-Architektur
	\begin{itemize}
		\item Verarbeitungsbefehle greifen nur zu Universalregistern (GPR General Purpose Register) zu. Damit können nur Load/Store-Befehle zum Speicher zugreifen
	\end{itemize}
	\item Festverdrahtete Steuerung
	\begin{itemize}
		\item Vorteil: geht schneller
		\item Nachteil: bei Änderungen in der Architektur muss neue festverdrahtete Steuerung erstellt werden
		\item[$\leftrightarrow$] Bei CISC Steuereung der Befehlsabarbeitung durch ein Mikroprogramm
	\end{itemize}
	\item Reduzierung der Prozessorhardware führt im Vergleich zu CISC zu kürzeren Entwicklungszeiten
	\begin{itemize}
		\item weniger Chipfläche
	\end{itemize}
\end{itemize}
\subsection{Beschränkungen bei DLX}
I-Typ-Befehlsformat
	\begin{itemize}
		\item Befehlswort wird in das IR (Instruction Register) geladen
		\item $ ^{IR0}Opcode^{IR|IR6}rs1^{IR10|IR11}rs2^{IR15|IR16}Immidiate^{IR31}$
	\end{itemize}
Welche Beschräkungen ergeben sich aus einer einheitlichen Befehlslänge von 32 Bit bei der DLX-Architektur?
\begin{itemize}
	\item[1] Bei den Direktoperanden sind wir auf 16 Bit begrenzt, obwohl wir eine Registerlänge von 32 Bit haben
	\begin{itemize}
		\item Nutzung von 2 Befehlen, um ein Register mit einem 32 Bit Direktoperanden zu laden
		\item LHI R10, 0x1234; lade höheres Halbwort mit Immediate 16; \\R10 $\leftarrow$ 0x1234 \#\# 0$^{16}$
		\item ADDUI R10, R10, 0x8678; Addiere unsigend immediate; unsigned verwendet automatisch Null-Erweiterung
		\begin{align*}
			&12340000\\
			+&00008678\\
			=&12348678
		\end{align*}
	\end{itemize}
	\item[2] nur 6 Bit für Operationscode $\to 2^6 = 64 $Befehle
	\item[3] nur 5 Bit für Kodierung des Registers $\to 2^5 = 32$ Register Kodierbar
	\item[2 $\leftrightarrow$ 3] mehr Register z.B.: $2^6 = 64$ bedeutet weniger Befehle $2^4 \to 16$ Befehle
\end{itemize}
\subsection{Zuordnung unter HDN}
Was versteht man unter einer vorzeichenerweiterten Zuordnung zu einem 32-Bit-Register und wie kann diese in HDN dargestellt werden?
\begin{itemize}
	\item vorzeichenerweiterte Zuordnung
	\begin{itemize}
		\item Problem: Direktoperand hat nur 16 Bit IR16\ldots 31
		\begin{itemize}
			\item wenn eine Operation mit einem 32-Bit-Register erfolgen soll muss der Direktoperand auf 32 Bit erweitert werden, ohne dass sich der Wert des Direktoperanden verändert
		\end{itemize}
		\item Lösung: Das MSB (Most Significant Bit) $IR_16$ muss 16 mal vor den Direktoperanden verkettet werden:\\
		$(IR_{16})^{} \#\# IR_{16 \ldots 31}$
		\begin{enumerate}
			\item $IR_{16} = 0 \to $ positive Zahl
			\item $IR_{16} = 1 \to $ negative Zahl (Zweierkomplement)
		\end{enumerate}
	\end{itemize}
\end{itemize}
\subsection{HDN Beschreibung I-Typ-DLX}
Interpretieren Sie die HDN-Beschreibung des I-Typ-DLX-Befehlsformates!
\begin{itemize}
	\item Immediate-ALU-Befehle
	\begin{itemize}
		\item GPR[rd] $\leftarrow$ GPR[rs1]op$((IR_{16})^{16}\#\# IR_{16\ldots 31}$
		\item Direktoperand $(IR_{16\ldots 32}$ wird vorzeichenerweitert und über der Operationscode op(ADD, SUB, MUL, AND, \ldots) mit dem Inhalt des GPR, dessen Nummer auf den Bitstellen 6 \ldots 10 (rs1) steht, verknüpft. Das Ergebnis wird mit dem GPR, dessen Nummer auf den Bitstellen 11\ldots 15 des Befehlsowrtes steht, abgespeichert. 
		\item Beispiel: ADDI rd,rs$_1$, 0xF43A; GPR[rd] $\leftarrow$ GPR[rs$_1$]+0xF43A
	\end{itemize}
	\item Lade-Speicher-Befehle
	\begin{itemize}
		\item Lade-Befehle
		\begin{itemize}
			\item GPR[rd]$\leftarrow$ M[GPR[rs$_1+((IR_{16})^{16}\#\# IR_{16\ldots 31})$]				\item Beispiel
			\begin{enumerate}
		\item LW rd, D(rs$_1$) allgemeine Darstellung
		\item LW R1, 10(R2) ; R! $\leftarrow$ M[10+R2]\#\# M[11+R2] \#\# M[12+R2] \#\# M[12+R2]
			\end{enumerate}
		\end{itemize}
		\item SPeicher-Befehle
		\begin{itemize}
			\item M(GPR[rs$_1$]+$((IR_{16})^{16}\#\# IR_{16\ldots 31})$]$\leftarrow$GPR(rs$_2$
		\end{itemize}
	\end{itemize}
	\item bedingte Verzweigung
	\begin{itemize}
		\item if/GPR[rs1] PC $\leftarrow$ PC + (($IR_{16})^{16} \#\# IR_{16 \ldots 31}$ \\ Wenn die Sprungbedingung erfüllt ist, wird de rPC um das vorzeichnerweiterte Immediate erhöht und somit gesprungen. Sprungbedingung:
		\begin{itemize}
			\item BEQZ (Brand EQual Zero) $\to$ Wert in rs1 = 0
			\item BNEQZ (Brand Not EQual Zero) $\to$ Wert in rs1 != 0
		\end{itemize}
	\end{itemize}
	\item Sprungbefehl mit Zieladresse im Register
	\begin{itemize}
		\item rd = 0, IR$_{16 \ldots 31} = 0$
		\item GPR[rs1] = Zieladresse des Sprungbefehls
		\item Die durch den PC estimmte Befehlsfolge wird verlassen und bei rs1 fortgesetzt (unbedingter Sprung)
	\end{itemize}
\end{itemize}
\subsection{DLX-Architektur}
Wo zeigen sich bei der DLX-Architektur besonders die Gestaltungsgrundsätze "Sparsamkeit" und "Orthogonalität"?
\begin{itemize}
	\item Sparsamkeit
	\begin{itemize}
		\item[$\to$] notewendig, da nur wenig Befehls-Kodierungen
		\item[Ziel:] möglichst mit einer Befehlskodierung mehrere Aufgaben erfüllen
		\item[Weg:] Register R0 hardwaremäßig auf = gesetzt
		\item Lade Speicher Befehle
		\begin{itemize}
			\item[z.B.:] LW rd, D(rs1) allg Darstellung \\ $\to$ LW R1, 10(R2); R1 $\leftarrow$ M[10+R2] \#\# M[11+R2] \#\# M[12+R2]\#\# M[13+R2],  Register indirekt mit Displacement \\ $\to$ LW R3, 100(R0) ; R3 $\leftarrow$ M[100] \#\# M[101] \#\# M[102] \#\# M[103] , Immediate Adress\\
			$\to$ LW R5,0(R6) ; R5 $\leftarrow$ M[R6]\#\#M[1+R6]\#\#M[2+R6]\#\#M[3+R6], Register Indirekt
			\item[z.B.:]
			\begin{itemize}
				\item SW D(rs1), rs2 allg. Darstellung
				\item SW 10(R3), R4 ; M[10+R3]\#\#M[11+R3]\#\#M[12+R3]\#\#M[13+R3] $\leftarrow$ R4, Register Indirekt mit Displacement
				\item SW 100(R0),R4 ;  M[100] \#\# M[101] \#\# M[102] \#\# M[103] $\leftarrow$ R4, Immediate Adress
				\item SW 0(R3), R4 ; M[R3]\#\#M[1+R3]\#\#M[2+R3]\#\#M[3+R3] $\leftarrow$ R4, Register Indirekt
			\end{itemize}
			Man kann mit diesem Befehl auch onch den Speicher mit 0 initialisieren
			\begin{itemize}
				\item SW D(rs1), R0 ; M[D+GPR[rs1]]\#\# M[1+D+GPR[rs1]]\#\#M[2+D+GPR[rs1]]\#\# M[3+D+GPR[rs1]] $\leftarrow$ R0
			\end{itemize}
		\end{itemize}
		\item R-Typ-Befehlsformat\\ z.B.: rd, rs1,rs2 allg. Darstellung
		\begin{itemize}
			\item Add R3,R2,R1 ; normale Addition R3 $\leftarrow$ R2+R1
			\item Add R3,R2,R0 ; Registertransfer R3 $\leftarrow$ R2
			\item Add R3,R0,R0 ; Clear Register R3 $\leftarrow 0^{32}$
		\end{itemize}
	\end{itemize}
	\item Orthogonalität \\Funktionell unabhängige Teilelemente müssen auch unabhängig voneinander spezifiziert und realisiert sein. \\$\to$ spezieller Befehl wird konstruiert durch freie Kombination der Befehlselemente:
	\begin{itemize}
		\item[1] Operation
		\item[2] Datentyp
		\item[3] Adressierungsart
		\item[4] Registernummern
	\end{itemize}
\end{itemize}
\subsection{DLX-Befehlsfolge mit HDN}
Kommentieren sie die folgende DLX-Befehlsfolge mit HDN!
\begin{itemize}
	\item ORI R5, R0, 0x102C ; R5 $\leftarrow_{32}$ R0 | 0x0000 102C \\danach in R5: 0x0000 102C
	\item LW R3, 0(R5) ; R3 $\leftarrow_{32}$ M[0+R5]\#\# M[1+R5]\#\# M[2+R5]\#\# M[3+R5] \\ist das Big Endian oder Little Endian? Um was geht es bei Big und Little Endian?
	\begin{itemize}
		\item Ablage der Daten im Hauptspeicher
		\item z.B.: im Regsiter steht 0x12345678
		\begin{itemize}
			\item Big Endian: Adressen sind Byteweise gespeichert, höherwertigstes byte (hier "12") zuerst
			\item Little Endian: Adressen auch hier Byteweise gespeichert, niedrigwertigstest byte (hier "78") zuerst
		\end{itemize}
	\end{itemize}
	$\to$ Adresse ist als Big Endian abgespeichert
	\item SUBI R2, R0, 5 ; R2 $\leftarrow_{32}$ R0 - 0x0000 0005\\-5 wird in R2 geladen
	\item loop: ADDI R2, R2, 1 ; R2 $\leftarrow_{32}$ R2 + 0x0000 0001 \\lege Anzahl der Schleifendurchläufe fest $\to$ 5 Schleifendurchläufe
	\item SW 0(R3), R4 ; M[0+R3]\#\# M[1+R3]\#\# M[2+R3]\#\# M[3+R3] $\leftarrow $ R4 \\ Inhalt von R4 wird ab der Speicheradresse gleaden, die in R3 steht
	\item ADDI R3, R3, 4 ; R3 $\leftarrow_{32}$ R3 + 0x0000 0004 \\ Inkrementierung der Speicheradresse in R3 um 4, damit in dem nächsten Schleifendurchlauf das nächste Wort (4 Byte) geschrieben werden kann
	\item BNEZ R2, loop ; Offsetsxt 16 $\leftarrow (IR_{16})^{16}$ \#\# $IR_{16\ldots 31}$ \\; name(loop) $\leftarrow$ PC + Offsetsxt 16$_{16\ldots 31}$ \\ ; if(R2 != 0) PC $\leftarrow$ name(loop) \\
	;nach 5 Durchläufen sit R0 = 0 $\to$ dann geht es weiter
	\item ADD R3, R0, R0 ; löschen von Register R3
\end{itemize}
fill ...
\section{fill - Blatt 4}
\subsection{fill}
\subsection{}
\begin{tabularx}{\textwidth}{|X|X|X|X|X|X|}
\hline
&Grad d &Druchmesser &Konnektivität &Halbierungs-breite &kleinste Erweiterung\\
\hline
Ring &2 &N/2 &2 &2 &1 \\
\hline
Vollst. Graph &N-1 &1 &N-1 &N$^2$/4 &1\\
\hline
Stern &1 bzw. N-1 &2 &1 &N/2 &1\\
\hline
Vollst. Binärbaum &1,2,3 &$2\cdot ld((N+1)/2)$ &1 &1 &N+1\\
\hline
2D-Torus &4 &$2\sqrt{N}/2$ &4 &&$2\sqrt{N}+1$\\
\hline
Hypercube &$ld(N)$ &$ld(N)$ &$ld(N)$ &N/2 &N\\
\hline
\end{tabularx}
\begin{itemize}
	\item Ring:
	\begin{itemize}
		\item einfaches Routing
		\item geringe Kosten $\to$ geringe Kabelmenge
		\item schlechte Skalierung
		\item leicht erweiterbar
	\end{itemize}
	\item Vollständiger Graph
	\begin{itemize}
		\item hohe Kosten $\to$ nur für kleine Netzwerke möglich
		\item kein Routing
		\item Ausfallsicherheit, schnell
	\end{itemize}
	\item Stern:
	\begin{itemize}
		\item leicht erweiterbar
		\item schnell
		\item viel Kabel in bezug auf Ring, Gitter
		\item wenn zentrale station ausfällt bricht Netz zusammen
	\end{itemize}
	\item vollst. Binärbaum
	\begin{itemize}
		\item schwachstelle ist Wurzelknoten
		\item relativ schwierig das auf Algorithmen abzuleiten $\to$ Anwendung für Broadcast
	\end{itemize}
	\item 2D Torus
	\begin{itemize}
		\item schnell gegenüber Gitter (halber Durchmesser)
		\item konstanter Grad (vorteil)
		\item Erweiterbarkeit geht noch (besser als Hyperscale, schlechter als Stern/Ring)
	\end{itemize}
	\item Hypercube
	\begin{itemize}
		\item kleiner Durchmesser (ld N)
		\item schlechte Erweiterbarkeit
	\end{itemize}
\end{itemize}
\subsection{Gitter Topologien}
\begin{tabularx}{\textwidth}{|X|X|X|X|}
\hline
&4x6 &3x8 &2x12\\
\hline
Grad &2,3,4 &2,3,4 &2,3\\
\hline
Durchmesser &8 &9 &12\\
\hline
Halbierungsbreite &4 &3 &2\\
\hline
\end{tabularx}
\subsection{Codierung - OMEGA Netz}
Routing
\begin{itemize}
	\item Destination Rooting
	\begin{itemize}
		\item Bitwertigkeiten ($b_0b_1b_2b_3$) entsprechend den jeweiligen Ausgängen (oberer/unterer) der Betazelle
		\begin{align*}
			&A_6 = 0110 = obA - uA - uA - obA
		\end{align*}
		\item Beispiele: $E_1 \to A_6$ und $E_{14}\to A_6$
	\end{itemize}
	\item XOR-Routing
	\begin{itemize}
		\item XOR-Verknüpfung von Quell und Zieladresse $\to$ ergibt Schalterstellung der jeweiligen Beta-Zelle (schräg = 1, gerade = 0):
		\begin{align*}
			&E_{14} \to A_6 \to 1110 \text{ XOR } 0110 = 1000\\
			&E_1 \to A_6 \to 0001 \text{ XOR } 0110 = 0111
		\end{align*}
	\end{itemize}
\end{itemize}
Blockierung im OMEGA-Netzwerk
\begin{itemize}
	\item Anzahl der Übereinstimmungen bei Blockierung $ld(E/A) = ld 16 = 4$
	\item Festellen einer Blockierung (in einem  4x2er Block Fenster stimmen alle 4 Spalten überein)
	\begin{align*}
		E_1 \to A_6 \text{ und }E_{14} \to A_6 = &0001 0110\\
		&1110 0110 \text{ 4.Stufe Blockierung am Ausgang A6}\\
		E_1 \to A_6 \text{ und }E_{13} \to A_1 = &0001 0110\\
		&1101 0001 \text{ keine Blockierung}\\
		E_2 \to A_{13} \text{ und } E_0 \to A_{12} = &0010 1101\\
		&1100 \text{ 3. Stufe Blockierung Ausgang A6}
	\end{align*}
\end{itemize}
\subsection{Prinzip Paketvermittlung}
\begin{itemize}
	\item Nachricht wird in Pakete geteilt
	\item Pakete werden unabhängig voneinander über das Netzwerk vom Sender zum Empfänger transportiert
	\item Paket besteht aus drei Teilen:\\
	\begin{itemize}
		\item Header (enthält Routing- und Kontrollinformationen)
		\item Datenteil (enthält Anteil der Nutzdaten/Gesamtnachricht)
		\item Endstück (Trailer: Fehlerkorrekturcode)
	\end{itemize}
	\item Drei Verfahren:
	\begin{itemize}
		\item Store-and-forward Prinzip
		\begin{itemize}
			\item gesamtes Paket wird zum Empfänger gesendet
			\item Jeder Zwischenknoten speichert das gesamte Paket (store), bevor es weitergesendet wird (forward)
			\item Vorteile:
			\begin{itemize}
				\item schnelle Freigabe von Verbindungen
			\end{itemize}
			\item Nachteile:
			\begin{itemize}
				\item großer latenzzeiten, hoher Speicheraufwand
			\end{itemize}
		\end{itemize}
		\item Virtual-Cut-Through-Verfahren (Infiniband)
		\begin{itemize}
			\item Pakete werden hier piplineartig durch das Netzwerk gesendet
			\item Prinzip:
			\begin{itemize}
				\item Flusssteuerung erfolgt nicht auf Paketbasis sondern auf der Basis wesentlich kleinerer pysikalischer Transporteinheiten, phits (physical units), die mann deshalb auch als flits (= phits = float control units) bezeichnet
				\item ein auf dem Übertragungspfad liegender Schalter (Knoten oder Router) betrachtet die ersten phits eines ankommenden Pakets (Routinginfos) $\to$ Entscheidung zu welchen Knoten das Paket weitergeleitet wird
				\item Ist Verbindung frei, dann wird der Header weitergeschickt
				\item restliches Paket wird hinterher geleitet $\to$ so dass phits des Paketes pipelineartig auf dem Übertragungspfad liegen
				\item Freigabe der Verbindung: $\to$ wenn alle phits des Paketes (einschließlich Endstück) vollständig übertragen wurden, wird die Verbindung freigegeben
			\end{itemize}
			\item Blockierungen:
			\begin{itemize}
				\item alle phits des Paketes werden im letzten erreichbaren Knoten aufgesammelt (store-and-forward-artig)
			\end{itemize}
			\item Vorteile
			\begin{itemize}
				\item geringere Latenzzeiten, aber man muss viel Speicher vorhalten
			\end{itemize}
		\end{itemize}
		\item Worm-Hole Routing
		\begin{itemize}
			\item unterscheidet sich vom Virtual Cut Through nur in der Behandlung von Blockierungen:
			\begin{itemize}
				\item Header blockeirt so lange bis Verbindung wieder frei ist
				\item alle nachfolgenden flits werden auch blockiert und verbleiben in ihrer Position $\to$ flits des Paketes liegen wie ein Wurm in der Leitung 
			\end{itemize}
			\item Vorteile:
			\begin{itemize}
				\item niedrige Latenzzeit
				\item am wenigsten Speicherbedarf
			\end{itemize}
			\item Nachteile:
			\begin{itemize}
				\item Verbindung blockiert komplett im Blockierungsfall
			\end{itemize}
		\end{itemize}
	\end{itemize}
\end{itemize}
Leitungsvermittlung
\begin{itemize}
	\item Leitung wird stationär aufgebaut $\to$ Overhead $\to$ ist für andere blockiert
	\item nach Aufbau kann man große Datenmengen drüber senden (gut für lange Nachrichten)
	\item Parallelrechner fast nicht, weil:
	\begin{itemize}
		\item vor allem kurze Nachrichten
	\end{itemize}
\end{itemize}
